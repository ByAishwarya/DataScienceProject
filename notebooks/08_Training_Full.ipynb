{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59650d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    r2_score,  \n",
    "    median_absolute_error, \n",
    "    explained_variance_score, \n",
    "    max_error\n",
    ")\n",
    "from tqdm.auto import tqdm \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c037d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD Full training data with all attributes \n",
    "X_train_full = pd.read_csv('../data/X_train_scaled.csv')\n",
    "X_test_full = pd.read_csv('../data/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('../data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('../data/y_test.csv').values.ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09deca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebaa433690f45fa9998f30388a7035f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "========================================================================================================================\n",
      "            Model   MAE  RMSE  R2 Score  Median AE  Variance Score  Max Error  Acc ±15 (%)  Train Time (s)  Pred Time (s)\n",
      "Linear Regression 11.98 16.83    0.3231       7.74          0.3231      79.91        71.03          0.2201         0.0144\n",
      " Ridge Regression 11.98 16.83    0.3231       7.74          0.3231      79.91        71.03          0.0934         0.0104\n",
      " Lasso Regression 12.00 16.83    0.3227       7.79          0.3227      79.97        71.04          0.3498         0.0028\n",
      "    Decision Tree 11.48 16.62    0.3396       7.02          0.3396      86.63        72.99          2.6058         0.0158\n",
      "    Random Forest 10.02 14.87    0.4716       6.27          0.4721      88.36        78.21        401.7237         1.5421\n",
      "Gradient Boosting 11.91 16.69    0.3342       7.72          0.3342      79.83        71.32         57.6381         0.0664\n",
      "========================================================================================================================\n",
      "\n",
      "BEST PERFORMING MODELS:\n",
      "--------------------------------------------------\n",
      "  MAE                 : Random Forest        (10.02)\n",
      "  RMSE                : Random Forest        (14.87)\n",
      "  Median AE           : Random Forest        (6.27)\n",
      "  Max Error           : Gradient Boosting    (79.83)\n",
      "  Train Time (s)      : Ridge Regression     (0.0934)\n",
      "  Pred Time (s)       : Lasso Regression     (0.0028)\n",
      "  R2 Score            : Random Forest        (0.4716)\n",
      "  Variance Score      : Random Forest        (0.4721)\n",
      "  Acc ±15 (%)         : Random Forest        (78.21)\n",
      "\n",
      "✓ Results saved to '../results/model_comparison.csv'\n"
     ]
    }
   ],
   "source": [
    "# 2. DEFINE PIPELINE\n",
    "def create_regression_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "# 3. INITIALIZE MODELS\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=0.1, random_state=42, max_iter=10000),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=70, random_state=42)\n",
    "}\n",
    "\n",
    "# 4. TRAIN AND EVALUATE\n",
    "results = []\n",
    "threshold = 15\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Evaluating Models\"):\n",
    "    pipeline = create_regression_pipeline(model)\n",
    "    \n",
    "    # Training Time\n",
    "    start_train = time.time()\n",
    "    pipeline.fit(X_train_full, y_train)\n",
    "    training_time = time.time() - start_train\n",
    "    \n",
    "    # Prediction Time\n",
    "    start_pred = time.time()\n",
    "    y_pred = pipeline.predict(X_test_full)\n",
    "    prediction_time = time.time() - start_pred\n",
    "    \n",
    "    # Metric Calculations\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    med_ae = median_absolute_error(y_test, y_pred)\n",
    "    var_score = explained_variance_score(y_test, y_pred)\n",
    "    m_error = max_error(y_test, y_pred)\n",
    "    within_threshold = np.mean(np.abs(y_test - y_pred) <= threshold) * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': round(mae, 2),\n",
    "        'RMSE': round(rmse, 2),\n",
    "        'R2 Score': round(r2, 4),\n",
    "        'Median AE': round(med_ae, 2),\n",
    "        'Variance Score': round(var_score, 4),\n",
    "        'Max Error': round(m_error, 2),\n",
    "        'Acc ±15 (%)': round(within_threshold, 2),\n",
    "        'Train Time (s)': round(training_time, 4),\n",
    "        'Pred Time (s)': round(prediction_time, 4)\n",
    "    })\n",
    "\n",
    "# 5. DISPLAY RESULTS\n",
    "performance_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*120)\n",
    "print(performance_df.to_string(index=False))\n",
    "print(\"=\"*120)\n",
    "\n",
    "# 6. BEST MODELS BY METRIC\n",
    "print(\"\\nBEST PERFORMING MODELS:\")\n",
    "print(\"-\" * 50)\n",
    "metrics_lower_better = ['MAE', 'RMSE', 'Median AE', 'Max Error', 'Train Time (s)', 'Pred Time (s)']\n",
    "metrics_higher_better = ['R2 Score', 'Variance Score', 'Acc ±15 (%)']\n",
    "\n",
    "for metric in metrics_lower_better:\n",
    "    best_model = performance_df.loc[performance_df[metric].idxmin(), 'Model']\n",
    "    best_value = performance_df[metric].min()\n",
    "    print(f\"  {metric:20s}: {best_model:20s} ({best_value})\")\n",
    "\n",
    "for metric in metrics_higher_better:\n",
    "    best_model = performance_df.loc[performance_df[metric].idxmax(), 'Model']\n",
    "    best_value = performance_df[metric].max()\n",
    "    print(f\"  {metric:20s}: {best_model:20s} ({best_value})\")\n",
    "\n",
    "# 7. SAVE RESULTS\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "performance_df.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Results saved to '../results/model_comparison.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b102c15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
