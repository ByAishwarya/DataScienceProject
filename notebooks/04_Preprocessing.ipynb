{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c122d6f2",
   "metadata": {},
   "source": [
    "# üìò Notebook 04: Data Preprocessing\n",
    "\n",
    "## üéØ What I Plan to Achieve in This Notebook\n",
    "\n",
    "In this notebook, I will prepare my raw Spotify dataset for machine learning by performing the following preprocessing steps:\n",
    "\n",
    "1. **Handle Missing Values** ‚Äì Identify and treat any null/NaN values in the dataset\n",
    "2. **Handle Duplicate Records** ‚Äì Remove or manage duplicate entries to ensure data integrity\n",
    "3. **Outlier Detection & Treatment** ‚Äì Address extreme values identified during EDA (especially in loudness, instrumentalness, speechiness)\n",
    "4. **Data Type Validation** ‚Äì Ensure all features have appropriate data types for modeling\n",
    "5. **Feature Engineering (Basic)** ‚Äì Create any derived features if needed based on EDA insights\n",
    "6. **Data Quality Checks** ‚Äì Verify data consistency and integrity before moving to encoding\n",
    "\n",
    "---\n",
    "\n",
    "## Why Preprocessing is Necessary\n",
    "\n",
    "### 1Ô∏è‚É£ **Machine Learning Models Cannot Handle \"Dirty\" Data**\n",
    "\n",
    "- Missing values break algorithms ‚Äì Most ML models (Random Forest, Linear Regression, etc.) cannot process NaN or null values\n",
    "- Duplicates cause data leakage ‚Äì Duplicate records can artificially inflate model performance during training and evaluation\n",
    "- Outliers distort patterns ‚Äì Extreme values can skew the model's understanding of normal data patterns\n",
    "\n",
    "### 2Ô∏è‚É£ **Based on My EDA Findings**\n",
    "\n",
    "From my exploratory analysis, I discovered several data quality issues:\n",
    "\n",
    "- **Outliers in multiple features:**\n",
    "  - `loudness` has extreme negative values below -40 dB\n",
    "  - `instrumentalness` shows many values concentrated at 1.0 (fully instrumental)\n",
    "  - `speechiness` has outliers above 0.8 (spoken word content)\n",
    "  - `liveness` shows unusual high values close to 1.0\n",
    "\n",
    "- **Weak feature correlations with target:**\n",
    "  - Highest correlation is only **0.1275** (instrumentalness)\n",
    "  - This suggests I may need feature engineering or interaction terms\n",
    "\n",
    "- **Bimodal distributions:**\n",
    "  - `acousticness` shows two distinct peaks (acoustic vs electric instruments)\n",
    "  - `energy` shows bimodal distribution (calm vs energetic tracks)\n",
    "\n",
    "### 3Ô∏è‚É£ **Ensures Model Reliability**\n",
    "\n",
    "- Improved generalization ‚Äì Clean data helps the model learn true patterns, not noise\n",
    "- Faster training ‚Äì Removing outliers and duplicates reduces computational overhead\n",
    "- Better interpretability ‚Äì Clean data makes it easier to understand model decisions\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Preprocessing Strategy\n",
    "\n",
    "Based on my EDA insights, I will adopt the following approach:\n",
    "\n",
    "### **Missing Values:**\n",
    "- First, check if any features have missing data\n",
    "- If found, decide between imputation(mean/median/mode) or deletion based on percentage of missing values\n",
    "\n",
    "### **Duplicates:**\n",
    "- Identify duplicate rows based on all features or specific key columns\n",
    "- Remove exact duplicates while preserving unique records\n",
    "\n",
    "### **Outliers:**\n",
    "- Use IQR (Interquartile Range) method to identify outliers\n",
    "- Use domain knowledge from EDA (e.g., loudness below -50 dB is unrealistic)\n",
    "- Either cap/floor extreme values or remove them (will decide based on impact)\n",
    "\n",
    "### **Data Type Validation:**\n",
    "- Ensure numerical features are `float64` or `int64`\n",
    "- Ensure categorical features (like `explicit`, `key`, `mode`) are properly typed\n",
    "- Convert `time_signature` if needed\n",
    "\n",
    "---\n",
    "\n",
    "## Important Note\n",
    "\n",
    "This notebook focuses **ONLY** on data cleaning and quality assurance. The following tasks will be handled in separate notebooks:\n",
    "\n",
    "- **Encoding categorical variables** ‚Üí Notebook 05\n",
    "- **Feature scaling/normalization** ‚Üí Notebook 06  \n",
    "- **Feature selection** ‚Üí Notebook 07\n",
    "- **Train-test split** ‚Üí Before modeling phase\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Expected Outcome\n",
    "\n",
    "By the end of this notebook, I will have:\n",
    "\n",
    "‚úÖ A clean dataset with **no missing values**  \n",
    "‚úÖ **No duplicate records**  \n",
    "‚úÖ **Outliers handled** appropriately  \n",
    "‚úÖ **Validated data types** for all features  \n",
    "‚úÖ A dataset ready for encoding and scaling in subsequent notebooks  \n",
    "\n",
    "This clean dataset will serve as the foundation for building robust machine learning models in the modeling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cfc64",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../assets/dividerlines.png\" width=\"600\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ea67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('../data/spotify_dedup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fda09",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "- Based on the dataset size ($n=89,740$), if missing values are less than 1%, I will drop them. Otherwise, apply median imputation for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd8bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Series([], dtype: int64)\n",
      "Shape after handling missing values: (89740, 23)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", null_counts[null_counts > 0])\n",
    "\n",
    "# Strategy: Drop rows with missing values (usually minimal in this dataset)\n",
    "df = df.dropna()\n",
    "print(f\"Shape after handling missing values: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23551171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CHECK: No missing values\n"
     ]
    }
   ],
   "source": [
    "missing = df.isnull().sum().sum()\n",
    "if missing == 0:\n",
    "    print(\"‚úÖ CHECK: No missing values\")\n",
    "else:\n",
    "    print(f\"‚ùå CHECK FAILED: {missing} missing values found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f2be1",
   "metadata": {},
   "source": [
    "### Checking for Duplicates\n",
    "I already removed the duplicates in 02_EDA_Statistical_Analysis.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3712c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicates: 0\n",
      "Duplicate Track IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Detailed duplicate check\n",
    "exact_duplicates = df.duplicated().sum()\n",
    "id_duplicates = df.duplicated(subset=['track_id']).sum()\n",
    "\n",
    "print(f\"Exact duplicates: {exact_duplicates}\")\n",
    "print(f\"Duplicate Track IDs: {id_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee02ca8",
   "metadata": {},
   "source": [
    "### Outlier Detection & Treatment\n",
    "From EDA,  loudness, instrumentalness, and speechiness have extreme distributions. We will use a \"Capping\" approach to handle outliers without losing the data points entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91943cde",
   "metadata": {},
   "source": [
    "#### What is Capping?\n",
    "*Capping (or Winsorization) means limiting extreme values to a defined boundary instead of removing them.*\n",
    "\n",
    "**Context:** You do *not* delete outlier rows; you replace extreme values with a reasonable maximum or minimum.\n",
    "\n",
    "*Example:*\n",
    "If your **loudness** lower bound is -25 and a song has loudness = -40, after capping:  \n",
    "`-40 ‚Üí -25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea1b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier treatment complete.\n"
     ]
    }
   ],
   "source": [
    "def handle_outliers_iqr(df, column):\n",
    "    # 1. Compute first and third quartiles\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    # 2. Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    # 3. Define lower and upper bounds using 1.5 * IQR rule\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Capping values at the bounds\n",
    "    #    Values below lower_bound ‚Üí set to lower_bound\n",
    "    #    Values above upper_bound ‚Üí set to upper_bound\n",
    "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    return df\n",
    "\n",
    "# Apply to specific features identified in EDA\n",
    "outlier_cols = ['loudness', 'speechiness', 'liveness']\n",
    "for col in outlier_cols:\n",
    "    df = handle_outliers_iqr(df, col)\n",
    "\n",
    "print(\"Outlier treatment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3615b2",
   "metadata": {},
   "source": [
    "Outliers were treated using an IQR-based capping approach. Instead of removing extreme observations, values beyond 1.5√óIQR were capped at the lower and upper bounds. This approach reduces the influence of extreme values while preserving the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a311344",
   "metadata": {},
   "source": [
    "### Data Type Validation\n",
    "Ensuring that booleans are integers and IDs are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4f5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0             int64\n",
      "track_id              object\n",
      "artists               object\n",
      "album_name            object\n",
      "track_name            object\n",
      "popularity             int64\n",
      "duration_ms            int64\n",
      "explicit               int64\n",
      "danceability         float64\n",
      "energy               float64\n",
      "key                    int64\n",
      "loudness             float64\n",
      "mode                   int64\n",
      "speechiness          float64\n",
      "acousticness         float64\n",
      "instrumentalness     float64\n",
      "liveness             float64\n",
      "valence              float64\n",
      "tempo                float64\n",
      "time_signature         int64\n",
      "track_genre           object\n",
      "duration_min         float64\n",
      "duration_category     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert explicit from bool to int (0/1)\n",
    "df['explicit'] = df['explicit'].astype(int)\n",
    "\n",
    "# Ensure track_genre and names are strings\n",
    "categorical_cols = ['track_id', 'artists', 'album_name', 'track_name', 'track_genre']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31726b",
   "metadata": {},
   "source": [
    "#### Feature Engineering (Basic)\n",
    "Since individual correlations with popularity are weak ($r < 0.15$), we will create interaction terms to help the model capture complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffdce6",
   "metadata": {},
   "source": [
    "This code performs feature engineering by creating interaction variables, binary categories, and log transforms to expose hidden patterns and normalize distributions within your music dataset. These transformations translate raw data into more descriptive signals, allowing machine learning models to learn faster and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521ebb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created. Total columns: 30\n"
     ]
    }
   ],
   "source": [
    "# A. Interaction Features\n",
    "df['energy_x_danceability'] = df['energy'] * df['danceability']\n",
    "df['loudness_x_energy'] = df['loudness'] * df['energy']\n",
    "df['valence_x_danceability'] = df['valence'] * df['danceability']\n",
    "\n",
    "# B. Binary Indicators (Based on EDA bimodal distributions)\n",
    "df['is_instrumental'] = (df['instrumentalness'] > 0.5).astype(int)\n",
    "df['has_vocals'] = (df['instrumentalness'] < 0.2).astype(int)\n",
    "df['is_speech_heavy'] = (df['speechiness'] > 0.33).astype(int)\n",
    "\n",
    "# C. Log Transforms for Skewed Data (if needed)\n",
    "# Adding a small constant to avoid log(0)\n",
    "df['tempo_log'] = np.log1p(df['tempo'])\n",
    "\n",
    "print(f\"New features created. Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a59955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of new features with Popularity:\n",
      " energy_x_danceability    0.038122\n",
      "loudness_x_energy        0.057023\n",
      "is_instrumental         -0.120739\n",
      "popularity               1.000000\n",
      "Name: popularity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_corr = df[['energy_x_danceability', 'loudness_x_energy', 'is_instrumental', 'popularity']].corr()['popularity']\n",
    "print(\"Correlation of new features with Popularity:\\n\", new_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0dcdd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns saved: 30\n"
     ]
    }
   ],
   "source": [
    "# Save the engineered dataset as a new checkpoint\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('../data/spotify_preprocessed.csv', index=False)\n",
    "print(f\"Total columns saved: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3312d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>duration_category</th>\n",
       "      <th>energy_x_danceability</th>\n",
       "      <th>loudness_x_energy</th>\n",
       "      <th>valence_x_danceability</th>\n",
       "      <th>is_instrumental</th>\n",
       "      <th>has_vocals</th>\n",
       "      <th>is_speech_heavy</th>\n",
       "      <th>tempo_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>3.844433</td>\n",
       "      <td>3‚Äì4 min</td>\n",
       "      <td>0.311636</td>\n",
       "      <td>-3.109906</td>\n",
       "      <td>0.483340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.487703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>2.493500</td>\n",
       "      <td>2‚Äì3 min</td>\n",
       "      <td>0.069720</td>\n",
       "      <td>-2.861010</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.362958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>3.513767</td>\n",
       "      <td>3‚Äì4 min</td>\n",
       "      <td>0.157242</td>\n",
       "      <td>-3.494506</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.348108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>3.365550</td>\n",
       "      <td>3‚Äì4 min</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>-1.081360</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.208064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>3.314217</td>\n",
       "      <td>3‚Äì4 min</td>\n",
       "      <td>0.273774</td>\n",
       "      <td>-4.288683</td>\n",
       "      <td>0.103206</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.795369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666         0   \n",
       "1            Ghost - Acoustic          55       149610         0   \n",
       "2              To Begin Again          57       210826         0   \n",
       "3  Can't Help Falling In Love          71       201933         0   \n",
       "4                     Hold On          82       198853         0   \n",
       "\n",
       "   danceability  energy  ...  track_genre  duration_min  duration_category  \\\n",
       "0         0.676  0.4610  ...     acoustic      3.844433            3‚Äì4 min   \n",
       "1         0.420  0.1660  ...     acoustic      2.493500            2‚Äì3 min   \n",
       "2         0.438  0.3590  ...     acoustic      3.513767            3‚Äì4 min   \n",
       "3         0.266  0.0596  ...     acoustic      3.365550            3‚Äì4 min   \n",
       "4         0.618  0.4430  ...     acoustic      3.314217            3‚Äì4 min   \n",
       "\n",
       "   energy_x_danceability  loudness_x_energy  valence_x_danceability  \\\n",
       "0               0.311636          -3.109906                0.483340   \n",
       "1               0.069720          -2.861010                0.112140   \n",
       "2               0.157242          -3.494506                0.052560   \n",
       "3               0.015854          -1.081360                0.038038   \n",
       "4               0.273774          -4.288683                0.103206   \n",
       "\n",
       "   is_instrumental  has_vocals  is_speech_heavy  tempo_log  \n",
       "0                0           1                0   4.487703  \n",
       "1                0           1                0   4.362958  \n",
       "2                0           1                0   4.348108  \n",
       "3                0           1                0   5.208064  \n",
       "4                0           1                0   4.795369  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
