{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Notebook 10: Model C â€“ Stacking Regressor\n",
    "\n",
    "## Overview\n",
    "This notebook implements a **Stacking (Stacked Generalization) Regressor** that combines predictions from multiple base models.\n",
    "\n",
    "### Stacking Architecture:\n",
    "```\n",
    "Level 0 (Base Models):\n",
    "â”œâ”€ Linear Regression (baseline)\n",
    "â”œâ”€ Ridge Regression (L2 regularization) \n",
    "â””â”€ Random Forest (non-linear ensemble)\n",
    "\n",
    "Level 1 (Meta-Model):\n",
    "â””â”€ Ridge Regression (learns optimal weights)\n",
    "```\n",
    "\n",
    "### Why Stacking?\n",
    "- **Combines strengths**: Linear for simple patterns, RF for complex\n",
    "- **Reduces variance**: Different models make different errors\n",
    "- **Better generalization**: Meta-model learns optimal weighting\n",
    "\n",
    "### Expected Improvement:\n",
    "- Target: RÂ² > 0.46 (better than RF's 0.457)\n",
    "- RMSE < 15.0 (better than RF's 15.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LIBRARY IMPORTS\n",
    "# ========================================\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Clean output\n",
    "\n",
    "# Base models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Stacking ensemble\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Model selection & tuning  \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,  # Primary metric\n",
    "    mean_absolute_error,       # Interpretable error\n",
    "    r2_score                   # Variance explained\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Timing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUAL STYLING (Spotify theme)\n",
    "# ========================================\n",
    "\n",
    "BG = '#e1ece3'      # Light mint background\n",
    "PRIMARY = '#62d089'  # Spotify green\n",
    "EMPHASIS = '#457e59' # Dark green\n",
    "GRID = '#a8b2a8'     # Subtle gray\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': BG,\n",
    "    'axes.facecolor': BG,\n",
    "    'axes.edgecolor': BG,\n",
    "    'axes.labelcolor': '#2b2b2b',\n",
    "    'xtick.color': '#2b2b2b',\n",
    "    'ytick.color': '#2b2b2b',\n",
    "    'grid.color': GRID,\n",
    "    'grid.alpha': 0.4,\n",
    "    'axes.grid': True,\n",
    "    'font.size': 11\n",
    "})\n",
    "\n",
    "sns.set_palette('Greens_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Load Data\n",
    "\n",
    "Using **Top 12 features** (best performer from Notebook 09):\n",
    "- RÂ² = 0.457 in Random Forest\n",
    "- 50% fewer features than Full set\n",
    "- Already scaled and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Data Size\n",
    "print(f\"X_train shape: {X_train.shape}\")  # Should be ~(80000, 12) for 100k total\n",
    "print(f\"X_test shape: {X_test.shape}\")    # Should be ~(20000, 12)\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f891fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Type and Memory usage\n",
    "print(\"\\nData types and memory usage:\")\n",
    "print(X_train.dtypes)\n",
    "print(f\"Memory: {X_train.memory_usage().sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA SUMMARY\n",
      "============================================================\n",
      "Training samples: 71,792\n",
      "Testing samples:  17,948\n",
      "Features: 12\n",
      "Target range: [0, 100]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# LOAD PREPROCESSED DATA\n",
    "# ========================================\n",
    "\n",
    "# Load target variable (popularity scores)\n",
    "y_train = pd.read_csv('../data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('../data/y_test.csv').values.ravel()\n",
    "\n",
    "# Load Top feature set (12 features)\n",
    "X_train = pd.read_csv('../data/X_train_top.csv')\n",
    "X_test = pd.read_csv('../data/X_test_top.csv')\n",
    "\n",
    "# Display data summary\n",
    "print(\"=\"*60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Testing samples:  {len(X_test):,}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Target range: [{int(y_train.min())}, {int(y_train.max())}]\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Hyperparameter Configuration\n",
    "\n",
    "### Grid Search Space:\n",
    "- **Ridge (base)**: alpha = [0.1, 1, 10, 100] â†’ 4 options\n",
    "- **Random Forest**:\n",
    "  - n_estimators = [100, 200, 300] â†’ 3 options\n",
    "  - max_depth = [10, 20, 30, None] â†’ 4 options\n",
    "  - min_samples_split = [2, 5, 10] â†’ 3 options\n",
    "- **Meta-model**: alpha = [0.1, 1, 10] â†’ 3 options\n",
    "\n",
    "**Total combinations**: 4 Ã— 3 Ã— 4 Ã— 3 Ã— 3 = **432 configurations**\n",
    "\n",
    "**With 5-fold CV**: 432 Ã— 5 = **2,160 model fits**\n",
    "\n",
    "**Expected time**: 45-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations: 432\n",
      "Total fits (with 5-fold CV): 2,160\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# ========================================\n",
    "# STEP 1: Tune Ridge separately\n",
    "# ========================================\n",
    "ridge = Ridge()\n",
    "ridge_grid = {'alpha': [0.1, 1, 10, 100]}\n",
    "ridge_search = GridSearchCV(ridge, ridge_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "ridge_search.fit(X_train, y_train)\n",
    "best_ridge = ridge_search.best_estimator_\n",
    "\n",
    "# ========================================\n",
    "# STEP 2: Tune Random Forest separately  \n",
    "# ========================================\n",
    "rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "rf_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_search = GridSearchCV(rf, rf_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "best_rf = rf_search.best_estimator_\n",
    "\n",
    "# ========================================\n",
    "# STEP 3: Create stacking with best models\n",
    "# ========================================\n",
    "estimators = [\n",
    "    ('ridge', best_ridge),\n",
    "    ('rf', best_rf)\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# STEP 4: Tune meta-model separately\n",
    "# ========================================\n",
    "stacking = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "meta_grid = {'final_estimator__alpha': [0.1, 1, 10]}\n",
    "stacking_search = GridSearchCV(stacking, meta_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "stacking_search.fit(X_train, y_train)\n",
    "\n",
    "best_stacking = stacking_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Build Stacking Ensemble\n",
    "\n",
    "### Base Models (Level 0):\n",
    "1. **Linear Regression**: Simple baseline, no hyperparameters\n",
    "2. **Ridge Regression**: L2 regularization, tunable alpha\n",
    "3. **Random Forest**: Non-linear, multiple hyperparameters\n",
    "\n",
    "### Meta-Model (Level 1):\n",
    "- **Ridge Regression**: Learns optimal weights for base predictions\n",
    "- Uses 5-fold CV to generate out-of-fold predictions\n",
    "- Prevents data leakage between levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models configured:\n",
      "  - linear: LinearRegression\n",
      "  - ridge: Ridge\n",
      "  - rf: RandomForestRegressor\n",
      "\n",
      "Meta-Model: Ridge\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DEFINE BASE MODELS (Level 0)\n",
    "# ========================================\n",
    "\n",
    "base_models = [\n",
    "    # 1. Linear Regression - baseline, no tuning\n",
    "    ('linear', LinearRegression()),\n",
    "    \n",
    "    # 2. Ridge - regularized linear model\n",
    "    ('ridge', Ridge(random_state=42)),\n",
    "    \n",
    "    # 3. Random Forest - non-linear ensemble\n",
    "    ('rf', RandomForestRegressor(\n",
    "        max_features='sqrt',     # Optimal from Notebook 09\n",
    "        min_samples_leaf=1,      # Optimal from Notebook 09\n",
    "        random_state=42,\n",
    "        n_jobs=-1               # Use all CPU cores\n",
    "    ))\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# DEFINE META-MODEL (Level 1)\n",
    "# ========================================\n",
    "\n",
    "meta_model = Ridge(random_state=42)\n",
    "\n",
    "print(\"Base Models configured:\")\n",
    "for name, model in base_models:\n",
    "    print(f\"  - {name}: {model.__class__.__name__}\")\n",
    "print(f\"\\nMeta-Model: {meta_model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccac82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# ========================================\n",
    "# 1. USE DEFAULT MODELS - NO TUNING\n",
    "# ========================================\n",
    "base_models = [\n",
    "    ('linear', LinearRegression()),\n",
    "    ('ridge', Ridge(alpha=1.0)),  # Default value\n",
    "    ('rf', RandomForestRegressor(\n",
    "        n_estimators=100,  # Small but reasonable\n",
    "        max_depth=20,      # Prevent overfitting\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# 2. CREATE STACKING WITH DEFAULT META\n",
    "# ========================================\n",
    "stacking = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 3. TRAIN ONCE - NO GRID SEARCH\n",
    "# ========================================\n",
    "print(\"Training stacking model (fast, no tuning)...\")\n",
    "stacking.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate immediately\n",
    "train_score = stacking.score(X_train, y_train)\n",
    "test_score = stacking.score(X_test, y_test)\n",
    "print(f\"Train RÂ²: {train_score:.4f}\")\n",
    "print(f\"Test RÂ²:  {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Train Model (Hyperparameter Search)\n",
    "\n",
    "**Warning**: This will take 45-90 minutes!\n",
    "\n",
    "### Process:\n",
    "1. Try all 432 hyperparameter combinations\n",
    "2. For each combination, perform 5-fold CV\n",
    "3. Select best configuration based on RMSE\n",
    "4. Retrain on full training set\n",
    "\n",
    "Progress will be shown with `verbose=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Start time: 15:21:50\n",
      "This will take 45-90 minutes...\n",
      "\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TRAIN MODEL (FAST)\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Start time: {time.strftime('%H:%M:%S')}\")\n",
    "print(\"This should take 10-20 minutes...\\n\")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train (single model, no grid search!)\n",
    "stacking_model.fit(X_train, y_train)  # â† SIMPLE FIT, NO GRIDSEARCH\n",
    "\n",
    "# Calculate duration\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"End time: {time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Duration: {duration/60:.1f} minutes\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef8661e",
   "metadata": {},
   "source": [
    "### Evaluation Predictions vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf36226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZE PREDICTIONS vs ACTUAL\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREDICTION VISUALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "y_train_pred = stacking_model.predict(X_train)\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"\\nTraining Metrics:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  RÂ²:   {train_r2:.4f}\")\n",
    "print(f\"  MAE:  {train_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nTesting Metrics:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  RÂ²:   {test_r2:.4f}\")\n",
    "print(f\"  MAE:  {test_mae:.4f}\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. Actual vs Predicted Scatter Plot (TEST SET)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.scatter(y_test, y_test_pred, alpha=0.5, s=20)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Values')\n",
    "ax1.set_ylabel('Predicted Values')\n",
    "ax1.set_title('Test Set: Actual vs Predicted')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add RÂ² text\n",
    "ax1.text(0.05, 0.95, f'RÂ² = {test_r2:.4f}', transform=ax1.transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Actual vs Predicted Scatter Plot (TRAIN SET)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.scatter(y_train, y_train_pred, alpha=0.3, s=10, color='green')\n",
    "ax2.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax2.set_xlabel('Actual Values')\n",
    "ax2.set_ylabel('Predicted Values')\n",
    "ax2.set_title('Train Set: Actual vs Predicted')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add RÂ² text\n",
    "ax2.text(0.05, 0.95, f'RÂ² = {train_r2:.4f}', transform=ax2.transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Residual Plot (TEST SET)\n",
    "residuals_test = y_test - y_test_pred\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "ax3.scatter(y_test_pred, residuals_test, alpha=0.5, s=20)\n",
    "ax3.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Predicted Values')\n",
    "ax3.set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax3.set_title('Test Set: Residual Plot')\n",
    "ax3.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for patterns in residuals\n",
    "from scipy import stats\n",
    "residual_mean = residuals_test.mean()\n",
    "residual_std = residuals_test.std()\n",
    "ax3.text(0.05, 0.95, f'Mean: {residual_mean:.3f}\\nStd: {residual_std:.3f}', \n",
    "         transform=ax3.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90acea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Error Distribution (TEST SET)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "n_bins = 50\n",
    "ax4.hist(residuals_test, bins=n_bins, edgecolor='black', alpha=0.7)\n",
    "ax4.set_xlabel('Residuals')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title(f'Test Set: Error Distribution\\n(n={len(residuals_test):,} samples)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add normal distribution overlay\n",
    "from scipy.stats import norm\n",
    "x = np.linspace(residuals_test.min(), residuals_test.max(), 100)\n",
    "pdf = norm.pdf(x, residual_mean, residual_std)\n",
    "scale_factor = len(residuals_test) * (residuals_test.max() - residuals_test.min()) / n_bins\n",
    "ax4.plot(x, pdf * scale_factor, 'r-', lw=2, label='Normal dist')\n",
    "ax4.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prediction Error by Actual Value (TEST SET)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "error_percent = np.abs(residuals_test) / (np.abs(y_test) + 1e-10) * 100  # Avoid division by zero\n",
    "ax5.scatter(y_test, error_percent, alpha=0.5, s=20)\n",
    "ax5.set_xlabel('Actual Value')\n",
    "ax5.set_ylabel('Error %')\n",
    "ax5.set_title('Test Set: Relative Error by Actual Value')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.set_ylim(0, min(200, error_percent.max() * 1.1))  # Cap at 200% for visibility\n",
    "\n",
    "# Add average error line\n",
    "avg_error_percent = error_percent.mean()\n",
    "ax5.axhline(y=avg_error_percent, color='r', linestyle='--', linewidth=2,\n",
    "           label=f'Avg: {avg_error_percent:.1f}%')\n",
    "ax5.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1149ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Comparison\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "models = ['Your Stacking', 'RF (Notebook 09)']\n",
    "rmse_scores = [test_rmse, 15.07]  # Your Notebook 09 result\n",
    "r2_scores = [test_r2, 0.0]  # Placeholder - replace with actual if available\n",
    "\n",
    "x_pos = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax6.bar(x_pos - width/2, rmse_scores, width, label='RMSE', color='skyblue')\n",
    "bars2 = ax6.bar(x_pos + width/2, r2_scores, width, label='RÂ²', color='lightcoral')\n",
    "\n",
    "ax6.set_xlabel('Model')\n",
    "ax6.set_ylabel('Score')\n",
    "ax6.set_title('Model Comparison')\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels(models)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.2f}', ha='center', va='bottom')\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f468a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ADDITIONAL METRICS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED ERROR ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate percentage within error ranges\n",
    "error_ranges = [1, 2, 5, 10, 20]\n",
    "for err in error_ranges:\n",
    "    within = np.sum(np.abs(residuals_test) <= err) / len(residuals_test) * 100\n",
    "    print(f\"Predictions within Â±{err}: {within:.1f}%\")\n",
    "\n",
    "# Calculate RÂ² for each base model individually\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INDIVIDUAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in stacking_model.named_estimators_.items():\n",
    "    pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    print(f\"{name:10s}: RÂ² = {r2:.4f}, RMSE = {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STACKING PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Stacking RÂ²:  {test_r2:.4f}\")\n",
    "print(f\"Stacking RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Best individual RÂ²: {max(r2_score(y_test, stacking_model.named_estimators_[name].predict(X_test)) for name in stacking_model.named_estimators_):.4f}\")\n",
    "print(f\"Improvement from stacking: {(test_r2 - max(r2_score(y_test, stacking_model.named_estimators_[name].predict(X_test)) for name in stacking_model.named_estimators_)):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
