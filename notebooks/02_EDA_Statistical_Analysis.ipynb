{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3269e315",
   "metadata": {},
   "source": [
    "# üìì Notebook 02: Exploratory Data Analysis (EDA) ‚Äî Statistical Analysis\n",
    "\n",
    "This notebook focuses on **statistical exploration** of the dataset before any modeling or feature engineering steps.  \n",
    "The goal is to understand the **structure, quality, and statistical behavior** of the data using quantitative measures.\n",
    "\n",
    "Previous focused on *data format and structure*, this notebook answers questions like:\n",
    "- Missing and duplicate values : \"HOW MANY nulls?\" + \"What % of data?\"\n",
    "- How are numerical features distributed?\n",
    "- Are there outliers or extreme values?\n",
    "- How do key features behave across different groups (e.g., genres)?\n",
    "- Do features use their full expected ranges?\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Libraries Used for Statistical Analysis\n",
    "\n",
    "### Why **NumPy** is Used\n",
    "\n",
    "**NumPy** (Numerical Python) is the **numerical computing in Python**.\n",
    "(some nerdy facts)\n",
    "- It was created in **2005** by **Travis Oliphant**\n",
    "- It evolved from earlier libraries called **Numeric** and **Numarray**\n",
    "- NumPy was created to provide:\n",
    "  - Fast numerical computation\n",
    "  - Efficient handling of large multi-dimensional arrays\n",
    "  - Vectorized operations written in C (much faster than Python loops)\n",
    "\n",
    "Most scientific Python libraries ‚Äî including **pandas, SciPy, scikit-learn**, and **matplotlib** ‚Äî are built **on top of NumPy**.\n",
    "\n",
    "In short:\n",
    "> NumPy provides the *numerical backbone* of the Python data science ecosystem.\n",
    "\n",
    "---\n",
    "\n",
    "### Why **pandas** Exists (and How It Differs from NumPy)\n",
    "\n",
    "**pandas** provide, which numpy doesnt:\n",
    "- Column names\n",
    "- Mixed data types\n",
    "- Missing values\n",
    "- Group-by operations\n",
    "- Time-series indexing\n",
    "\n",
    "#### Key Differences Between NumPy and pandas\n",
    "\n",
    "| Aspect | NumPy | pandas |\n",
    "|------|------|-------|\n",
    "| Core structure | `ndarray` | `DataFrame` / `Series` |\n",
    "| Data types | Mostly homogeneous | Heterogeneous (mixed types) |\n",
    "| Column labels | ‚ùå No | ‚úÖ Yes |\n",
    "| Missing values | Limited support | Native support |\n",
    "| Grouped operations | Manual | Built-in (`groupby`) |\n",
    "| Use case | Low-level numerical computing | High-level data analysis |\n",
    "\n",
    "**Relationship between them**:\n",
    "> pandas uses NumPy internally, but adds **labels, alignment, and data-awareness**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç My Scope of Statistical Analysis in This Notebook\n",
    "\n",
    "Performs a **systematic statistical audit** of the dataset using the following analyses:\n",
    "\n",
    "### ‚úÖ This notebook covers\n",
    "\n",
    "1. **Missing Values Analysis**  \n",
    "   Count and percentage of missing values per feature.\n",
    "\n",
    "2. **Duplicate Rows Check**  \n",
    "   Identification of exact duplicate records.\n",
    "\n",
    "3. **Unique Values Count per Column**  \n",
    "   Helps distinguish categorical, identifier, and continuous variables.\n",
    "\n",
    "4. **Correlation Matrix (Numerical Features)**  \n",
    "   Measures linear relationships between numerical features.\n",
    "\n",
    "5. **Skewness Analysis**  \n",
    "   Examines the asymmetry of feature distributions.\n",
    "\n",
    "6. **Outlier Detection using IQR Method**  \n",
    "   Identifies extreme values based on interquartile range.\n",
    "\n",
    "7. **Feature-wise Descriptive Statistics**  \n",
    "   Minimum, maximum, and range for numerical features.\n",
    "\n",
    "8. **Grouped Statistics by Genre**  \n",
    "   Mean values of popularity, energy, danceability, and other features grouped by genre.\n",
    "\n",
    "9. **Explicit vs Non-Explicit Comparison**  \n",
    "   Statistical comparison of audio features and popularity.\n",
    "\n",
    "10. **Key Distribution Analysis**  \n",
    "    Frequency analysis of musical keys.\n",
    "\n",
    "11. **Duration Analysis**  \n",
    "    Statistical patterns in track length (milliseconds).\n",
    "\n",
    "12. **Percentile Analysis**  \n",
    "    Analysis at 25th, 50th, 75th, 90th, and 99th percentiles.\n",
    "\n",
    "13. **Variance and Standard Deviation Analysis**  \n",
    "    Measures feature spread and variability.\n",
    "\n",
    "14. **Zero and Near-Zero Value Detection**  \n",
    "    Identifies features with low-information or constant values.\n",
    "\n",
    "15. **Coefficient of Variation (CV)**  \n",
    "    Relative variability normalized by mean (useful for feature comparison).\n",
    "---\n",
    "\n",
    "## üéØ Outcome of This Notebook\n",
    "\n",
    "By the end of this notebook, we will have:\n",
    "- A statistically validated understanding of the dataset\n",
    "- Identified potential data quality issues\n",
    "- Insights into feature distributions and variability\n",
    "- give strong foundation for **EDA visualization and modeling** in subsequent notebooks\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70096b0",
   "metadata": {},
   "source": [
    "**Note:** This notebook focuses on **statistical analysis only**. Visualizations are in Notebook 03."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2355bb",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    " <img src=\"../assets/dividerlines.png\" width=\"600\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcfdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computations (percentiles, IQR calculations)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e81587",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Missing Values Analysis\n",
    "\n",
    "**Why?** Understanding missing data helps us decide:\n",
    "- Which columns need imputation (filling missing values)\n",
    "- Which columns might need to be dropped\n",
    "- Data quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ffc297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MISSING VALUES ANALYSIS\n",
      "==================================================\n",
      "                  Missing_Count  Missing_Percentage\n",
      "artists                       1                 0.0\n",
      "track_name                    1                 0.0\n",
      "album_name                    1                 0.0\n",
      "Unnamed: 0                    0                 0.0\n",
      "track_id                      0                 0.0\n",
      "popularity                    0                 0.0\n",
      "duration_ms                   0                 0.0\n",
      "explicit                      0                 0.0\n",
      "danceability                  0                 0.0\n",
      "energy                        0                 0.0\n",
      "key                           0                 0.0\n",
      "loudness                      0                 0.0\n",
      "mode                          0                 0.0\n",
      "speechiness                   0                 0.0\n",
      "acousticness                  0                 0.0\n",
      "instrumentalness              0                 0.0\n",
      "liveness                      0                 0.0\n",
      "valence                       0                 0.0\n",
      "tempo                         0                 0.0\n",
      "time_signature                0                 0.0\n",
      "track_genre                   0                 0.0\n",
      "==================================================\n",
      "\n",
      "üîç Columns with missing values: 3\n",
      "üìà Total missing values: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Total number of rows in dataset\n",
    "total = len(df)\n",
    "\n",
    "# Count of missing values per column\n",
    "missing_count = df.isnull().sum()\n",
    "\n",
    "# Percentage of missing values per column\n",
    "missing_pct = (missing_count / total) * 100\n",
    "\n",
    "# Combine into a DataFrame for better readability\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_count,\n",
    "    'Missing_Percentage': missing_pct.round(2)\n",
    "})\n",
    "\n",
    "# Sort by missing count (descending) to see problematic columns first\n",
    "missing_df = missing_df.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"üìä MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(missing_df)\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nüîç Columns with missing values: {(missing_count > 0).sum()}\")\n",
    "print(f\"üìà Total missing values: {missing_count.sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1decb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping missing: 113,999\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Verify\n",
    "print(f\"Rows after dropping missing: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08d514",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Duplicate Rows Check\n",
    "\n",
    "**Why?** Duplicate entries can:\n",
    "- Bias our model (same song counted multiple times)\n",
    "- Inflate dataset size artificially\n",
    "- Affect statistical calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09b17115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATE ROWS ANALYSIS\n",
      "Total duplicate rows: 0\n",
      "Percentage of dataset: 0.00%\n",
      "\n",
      "Duplicate track_ids: 24,259 üò±\n"
     ]
    }
   ],
   "source": [
    "# Count total duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "\n",
    "# Percentage of duplicates\n",
    "duplicate_pct = (duplicate_count / len(df)) * 100\n",
    "\n",
    "print(\"DUPLICATE ROWS ANALYSIS\")\n",
    "print(f\"Total duplicate rows: {duplicate_count:,}\")\n",
    "print(f\"Percentage of dataset: {duplicate_pct:.2f}%\")\n",
    "\n",
    "# check duplicates based on track_id (should be unique)\n",
    "track_id_duplicates = df['track_id'].duplicated().sum()\n",
    "print(f\"\\nDuplicate track_ids: {track_id_duplicates:,} üò±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e369064",
   "metadata": {},
   "source": [
    "### My Finding:\n",
    "- 114,000 rows √∑ 114 genres = 1,000 tracks per genre\n",
    "- 89,741 unique tracks ‚Üí Same song appears in multiple genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9275a132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_genre\n",
       "1    73441\n",
       "2    11424\n",
       "3     2955\n",
       "4     1361\n",
       "5      431\n",
       "6      104\n",
       "7       21\n",
       "8        2\n",
       "9        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check: Same track_id but different genres?\n",
    "df.groupby('track_id')['track_genre'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0a84a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks appearing in multiple genres: 16299\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001APMDOl3qtx1526T11n1</td>\n",
       "      <td>Better</td>\n",
       "      <td>Pink Sweat$;Kirby</td>\n",
       "      <td>[chill, soul]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001YQlnDSduXd5LgBd66gT</td>\n",
       "      <td>El Tiempo Es Dinero - Remasterizado 2007</td>\n",
       "      <td>Soda Stereo</td>\n",
       "      <td>[punk-rock, ska]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003vvx7Niy0yvhvHt4a68B</td>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>[alt-rock, alternative, rock]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004h8smbIoAkUNDJvVKwkG</td>\n",
       "      <td>Lovemark</td>\n",
       "      <td>Ouse;Powfu</td>\n",
       "      <td>[emo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006rHBBNLJMpQs8fRC2GDe</td>\n",
       "      <td>Agora Estou Sofrendo - Ao Vivo</td>\n",
       "      <td>Calcinha Preta;Gusttavo Lima</td>\n",
       "      <td>[forro, pagode, sertanejo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>006tmNZLXEXPqdb23wwSN1</td>\n",
       "      <td>Yemye≈üil Bir Deniz</td>\n",
       "      <td>ƒ∞lhan ƒ∞rem</td>\n",
       "      <td>[j-pop, j-rock, jazz, turkish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00970cTs7LnxWt0d5Qk08m</td>\n",
       "      <td>Sleigh Ride</td>\n",
       "      <td>Ella Fitzgerald</td>\n",
       "      <td>[blues, jazz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00B7SBwrjbycLMOgAmeIU8</td>\n",
       "      <td>Reach Out</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>[alt-rock, funk, metal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00EsQxsJv6vy7hEQN3jZWG</td>\n",
       "      <td>Beginning Middle End - Always and Forever Mix)...</td>\n",
       "      <td>Leah Nobel</td>\n",
       "      <td>[singer-songwriter, songwriter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00GVRTIWMjYwwHEjTLclgf</td>\n",
       "      <td>Home</td>\n",
       "      <td>Robert Hood</td>\n",
       "      <td>[chicago-house, detroit-techno]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                         track_name  \\\n",
       "0  001APMDOl3qtx1526T11n1                                             Better   \n",
       "1  001YQlnDSduXd5LgBd66gT           El Tiempo Es Dinero - Remasterizado 2007   \n",
       "2  003vvx7Niy0yvhvHt4a68B                                     Mr. Brightside   \n",
       "3  004h8smbIoAkUNDJvVKwkG                                           Lovemark   \n",
       "4  006rHBBNLJMpQs8fRC2GDe                     Agora Estou Sofrendo - Ao Vivo   \n",
       "5  006tmNZLXEXPqdb23wwSN1                                 Yemye≈üil Bir Deniz   \n",
       "6  00970cTs7LnxWt0d5Qk08m                                        Sleigh Ride   \n",
       "7  00B7SBwrjbycLMOgAmeIU8                                          Reach Out   \n",
       "8  00EsQxsJv6vy7hEQN3jZWG  Beginning Middle End - Always and Forever Mix)...   \n",
       "9  00GVRTIWMjYwwHEjTLclgf                                               Home   \n",
       "\n",
       "                        artists                      track_genre  \n",
       "0             Pink Sweat$;Kirby                    [chill, soul]  \n",
       "1                   Soda Stereo                 [punk-rock, ska]  \n",
       "2                   The Killers    [alt-rock, alternative, rock]  \n",
       "3                    Ouse;Powfu                       [emo, sad]  \n",
       "4  Calcinha Preta;Gusttavo Lima       [forro, pagode, sertanejo]  \n",
       "5                    ƒ∞lhan ƒ∞rem   [j-pop, j-rock, jazz, turkish]  \n",
       "6               Ella Fitzgerald                    [blues, jazz]  \n",
       "7         Red Hot Chili Peppers          [alt-rock, funk, metal]  \n",
       "8                    Leah Nobel  [singer-songwriter, songwriter]  \n",
       "9                   Robert Hood  [chicago-house, detroit-techno]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# group by track_id and count unique genres\n",
    "multi_genre_tracks = (\n",
    "    df.groupby('track_id')['track_genre']\n",
    "      .nunique()\n",
    "      .reset_index(name='genre_count')\n",
    ")\n",
    "\n",
    "# keep only tracks with more than 1 genre\n",
    "multi_genre_tracks = multi_genre_tracks[multi_genre_tracks['genre_count'] > 1]\n",
    "\n",
    "print(f\"Number of tracks appearing in multiple genres: {len(multi_genre_tracks)}\")\n",
    "\n",
    "multi_genre_details = (\n",
    "    df[df['track_id'].isin(multi_genre_tracks['track_id'])]\n",
    "    .groupby(['track_id', 'track_name', 'artists'])['track_genre']\n",
    "    .unique()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "multi_genre_details.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d9228dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>genre_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74275</th>\n",
       "      <td>6S3JlDAGk3uu3NtZbPnuhS</td>\n",
       "      <td>Baby Blue - Remastered 2010</td>\n",
       "      <td>Badfinger</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25739</th>\n",
       "      <td>2Ey6v4Sekh3Z0RUSISRosD</td>\n",
       "      <td>Layla</td>\n",
       "      <td>Derek &amp; The Dominos</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31723</th>\n",
       "      <td>2kkvB3RNRzwjFdGhaUA0tz</td>\n",
       "      <td>Layla</td>\n",
       "      <td>Derek &amp; The Dominos</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88605</th>\n",
       "      <td>7tbzfR8ZvZzJEzy6v0d6el</td>\n",
       "      <td>Liggi</td>\n",
       "      <td>Ritviz</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>0e5LcankE0UyJUuCoq1uH2</td>\n",
       "      <td>The Joker</td>\n",
       "      <td>Steve Miller Band</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49041</th>\n",
       "      <td>4GPQDyw9hC1DiZVh0ouDVL</td>\n",
       "      <td>Keep My Name Outta Your Mouth</td>\n",
       "      <td>The Black Keys</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59519</th>\n",
       "      <td>5BI1XqMJK91dsEq0Bfe0Ov</td>\n",
       "      <td>Show Me The Way</td>\n",
       "      <td>Peter Frampton</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58364</th>\n",
       "      <td>54zCdkbIALAnv8Ihi3XWlD</td>\n",
       "      <td>Stay Alive</td>\n",
       "      <td>Jos√© Gonz√°lez</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35737</th>\n",
       "      <td>36NwMJRaCy7x77xYGJiG2M</td>\n",
       "      <td>Midnight Rider</td>\n",
       "      <td>Allman Brothers Band</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29766</th>\n",
       "      <td>2aaClnypAakdAmLw74JXxB</td>\n",
       "      <td>Arise</td>\n",
       "      <td>Sepultura</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id                     track_name  \\\n",
       "74275  6S3JlDAGk3uu3NtZbPnuhS    Baby Blue - Remastered 2010   \n",
       "25739  2Ey6v4Sekh3Z0RUSISRosD                          Layla   \n",
       "31723  2kkvB3RNRzwjFdGhaUA0tz                          Layla   \n",
       "88605  7tbzfR8ZvZzJEzy6v0d6el                          Liggi   \n",
       "7396   0e5LcankE0UyJUuCoq1uH2                      The Joker   \n",
       "49041  4GPQDyw9hC1DiZVh0ouDVL  Keep My Name Outta Your Mouth   \n",
       "59519  5BI1XqMJK91dsEq0Bfe0Ov                Show Me The Way   \n",
       "58364  54zCdkbIALAnv8Ihi3XWlD                     Stay Alive   \n",
       "35737  36NwMJRaCy7x77xYGJiG2M                 Midnight Rider   \n",
       "29766  2aaClnypAakdAmLw74JXxB                          Arise   \n",
       "\n",
       "                    artists  genre_count  \n",
       "74275             Badfinger            9  \n",
       "25739   Derek & The Dominos            8  \n",
       "31723   Derek & The Dominos            8  \n",
       "88605                Ritviz            7  \n",
       "7396      Steve Miller Band            7  \n",
       "49041        The Black Keys            7  \n",
       "59519        Peter Frampton            7  \n",
       "58364         Jos√© Gonz√°lez            7  \n",
       "35737  Allman Brothers Band            7  \n",
       "29766             Sepultura            7  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by songs with the highest number of genres\n",
    "multi_genre_sorted = (\n",
    "    df.groupby(['track_id', 'track_name', 'artists'])['track_genre']\n",
    "      .nunique()\n",
    "      .reset_index(name='genre_count')\n",
    "      .sort_values(by='genre_count', ascending=False)\n",
    ")\n",
    "\n",
    "multi_genre_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ac746",
   "metadata": {},
   "source": [
    "\"For songs that appear in multiple genres (same track_id), does their popularity score vary across different genre listings, or is it consistent regardless of genre? This will help us understand if popularity is track-specific or genre-dependent in duplicate entries.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef5e5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0           ‚Üí Duplicates:        0 (  0.00%)\n",
      "track_id             ‚Üí Duplicates:   24,259 ( 21.28%)\n",
      "artists              ‚Üí Duplicates:   82,562 ( 72.42%)\n",
      "album_name           ‚Üí Duplicates:   67,410 ( 59.13%)\n",
      "track_name           ‚Üí Duplicates:   40,391 ( 35.43%)\n",
      "popularity           ‚Üí Duplicates:  113,898 ( 99.91%)\n",
      "duration_ms          ‚Üí Duplicates:   63,303 ( 55.53%)\n",
      "explicit             ‚Üí Duplicates:  113,997 (100.00%)\n",
      "danceability         ‚Üí Duplicates:  112,825 ( 98.97%)\n",
      "energy               ‚Üí Duplicates:  111,916 ( 98.17%)\n",
      "key                  ‚Üí Duplicates:  113,987 ( 99.99%)\n",
      "loudness             ‚Üí Duplicates:   94,519 ( 82.91%)\n",
      "mode                 ‚Üí Duplicates:  113,997 (100.00%)\n",
      "speechiness          ‚Üí Duplicates:  112,510 ( 98.69%)\n",
      "acousticness         ‚Üí Duplicates:  108,938 ( 95.56%)\n",
      "instrumentalness     ‚Üí Duplicates:  108,653 ( 95.31%)\n",
      "liveness             ‚Üí Duplicates:  112,277 ( 98.49%)\n",
      "valence              ‚Üí Duplicates:  112,209 ( 98.43%)\n",
      "tempo                ‚Üí Duplicates:   68,347 ( 59.95%)\n",
      "time_signature       ‚Üí Duplicates:  113,994 (100.00%)\n",
      "track_genre          ‚Üí Duplicates:  113,885 ( 99.90%)\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    duplicate_count = df[col].duplicated().sum()\n",
    "    duplicate_pct = (duplicate_count / len(df)) * 100\n",
    "    \n",
    "    print(\n",
    "        f\"{col:20s} ‚Üí \"\n",
    "        f\"Duplicates: {duplicate_count:8,} \"\n",
    "        f\"({duplicate_pct:6.2f}%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3c8ea",
   "metadata": {},
   "source": [
    "My Observation:\n",
    "- Duplicate values of these variable, isnt duplicate entries/rows\n",
    "- repeated values within individual feature like artists, loudness,tempo: is OK\n",
    "- Categorical columns like (explicit, mode, key, track_genre): Naturally have very high duplicate percentages because they have few possible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e33110",
   "metadata": {},
   "source": [
    "### Note\n",
    "‚úîÔ∏è This analysis shows value repetition, not row duplication\n",
    "‚ùå It does NOT mean the dataset is flawed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7a088",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "A song like **‚ÄúBetter‚Äù by Pink Sweat$ (feat. Kirby)** appears multiple times in the dataset because it is associated with more than one genre, such as:\n",
    "\n",
    "- chill  \n",
    "- soul  \n",
    "\n",
    "As a result, the same track is repeated once for each genre it belongs to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45192215",
   "metadata": {},
   "source": [
    "### Options I Have\n",
    "\n",
    "#### Option A: SPlit Data\n",
    "I can split my data into unique songs & duplicated songs (with multiple genres), and perform EDAs separately.\n",
    "- Dataset 1: `unique_songs.csv` (73,441 songs) ‚Üí Songs in **1 genre only**\n",
    "- Dataset 2: `multi_genre_songs.csv` (16,299 songs) ‚Üí Songs in 2+ genres\n",
    "> This would *complicate* my workflow\n",
    "\n",
    "#### Option B: Drop the Duplicates\n",
    "Since I have **89,740** unique tracks! Which is a *good* number of datasets to feed to the model, to keep it simple and focused I am dropping the duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5c504",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "055fc573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deduplication: 113,999\n",
      "Rows after deduplication:  89,740\n",
      "Tracks removed:            24,259\n"
     ]
    }
   ],
   "source": [
    "# number of rows before deduplication\n",
    "rows_before = len(df)\n",
    "\n",
    "# drop duplicates, keeping the first occurrence\n",
    "df_dedup = df.drop_duplicates(subset='track_id', keep='first')\n",
    "\n",
    "# number of rows after deduplication\n",
    "rows_after = len(df_dedup)\n",
    "\n",
    "print(f\"Rows before deduplication: {rows_before:,}\")\n",
    "print(f\"Rows after deduplication:  {rows_after:,}\")\n",
    "print(f\"Tracks removed:            {rows_before - rows_after:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77e619a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After deduplication, always reset the index!\n",
    "df_dedup = df_dedup.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e85bf4",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Unique Values Count\n",
    "\n",
    "**Why?** Helps identify:\n",
    "- High cardinality columns (many unique values - may need special handling)\n",
    "- Low cardinality columns (few categories - good for encoding)\n",
    "- Constant columns (only 1 value - useless for prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aef3d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä UNIQUE VALUES PER COLUMN\n",
      "                  Unique_Count  Unique_Percentage\n",
      "Unnamed: 0               89740             100.00\n",
      "track_id                 89740             100.00\n",
      "track_name               73608              82.02\n",
      "duration_ms              50696              56.49\n",
      "album_name               46589              51.92\n",
      "tempo                    45652              50.87\n",
      "artists                  31437              35.03\n",
      "loudness                 19480              21.71\n",
      "instrumentalness          5346               5.96\n",
      "acousticness              5061               5.64\n",
      "energy                    2083               2.32\n",
      "valence                   1790               1.99\n",
      "liveness                  1722               1.92\n",
      "speechiness               1489               1.66\n",
      "danceability              1174               1.31\n",
      "track_genre                113               0.13\n",
      "popularity                 101               0.11\n",
      "key                         12               0.01\n",
      "time_signature               5               0.01\n",
      "mode                         2               0.00\n",
      "explicit                     2               0.00\n"
     ]
    }
   ],
   "source": [
    "# Count how many unique values exist in each column in the new dataset\n",
    "# Get unique counts for all columns\n",
    "unique_counts = df_dedup.nunique()\n",
    "\n",
    "# Create DataFrame with unique counts and percentage\n",
    "unique_df = pd.DataFrame({\n",
    "    'Unique_Count': unique_counts,\n",
    "    'Unique_Percentage': ((unique_counts / len(df_dedup)) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Sort by unique count\n",
    "unique_df = unique_df.sort_values('Unique_Count', ascending=False)\n",
    "\n",
    "print(\"üìä UNIQUE VALUES PER COLUMN\")\n",
    "print(unique_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda9ceb",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Correlation Matrix\n",
    "\n",
    "**Why?** Correlation tells us:\n",
    "- Which features are related to our target (popularity)\n",
    "- Which features are related to each other (multicollinearity)\n",
    "- Potential feature engineering opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d063ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CORRELATION MATRIX\n",
      "================================================================================\n",
      "                  popularity  duration_ms  danceability  energy   key  \\\n",
      "popularity              1.00        -0.02          0.06    0.01  0.00   \n",
      "duration_ms            -0.02         1.00         -0.06    0.06  0.01   \n",
      "danceability            0.06        -0.06          1.00    0.14  0.04   \n",
      "energy                  0.01         0.06          0.14    1.00  0.05   \n",
      "key                     0.00         0.01          0.04    0.05  1.00   \n",
      "loudness                0.07         0.00          0.27    0.76  0.04   \n",
      "mode                   -0.02        -0.04         -0.06   -0.08 -0.14   \n",
      "speechiness            -0.05        -0.06          0.11    0.14  0.02   \n",
      "acousticness           -0.04        -0.11         -0.18   -0.73 -0.05   \n",
      "instrumentalness       -0.13         0.12         -0.19   -0.18 -0.01   \n",
      "liveness               -0.01         0.01         -0.13    0.19 -0.00   \n",
      "valence                -0.01        -0.15          0.49    0.26  0.03   \n",
      "tempo                   0.01         0.03         -0.02    0.26  0.01   \n",
      "time_signature          0.04         0.02          0.21    0.19  0.01   \n",
      "\n",
      "                  loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
      "popularity            0.07 -0.02        -0.05         -0.04             -0.13   \n",
      "duration_ms           0.00 -0.04        -0.06         -0.11              0.12   \n",
      "danceability          0.27 -0.06         0.11         -0.18             -0.19   \n",
      "energy                0.76 -0.08         0.14         -0.73             -0.18   \n",
      "key                   0.04 -0.14         0.02         -0.05             -0.01   \n",
      "loudness              1.00 -0.04         0.06         -0.58             -0.43   \n",
      "mode                 -0.04  1.00        -0.04          0.09             -0.05   \n",
      "speechiness           0.06 -0.04         1.00          0.01             -0.10   \n",
      "acousticness         -0.58  0.09         0.01          1.00              0.10   \n",
      "instrumentalness     -0.43 -0.05        -0.10          0.10              1.00   \n",
      "liveness              0.08  0.02         0.23         -0.02             -0.09   \n",
      "valence               0.29  0.03         0.03         -0.10             -0.33   \n",
      "tempo                 0.23 -0.00         0.00         -0.22             -0.06   \n",
      "time_signature        0.19 -0.02        -0.01         -0.17             -0.08   \n",
      "\n",
      "                  liveness  valence  tempo  time_signature  \n",
      "popularity           -0.01    -0.01   0.01            0.04  \n",
      "duration_ms           0.01    -0.15   0.03            0.02  \n",
      "danceability         -0.13     0.49  -0.02            0.21  \n",
      "energy                0.19     0.26   0.26            0.19  \n",
      "key                  -0.00     0.03   0.01            0.01  \n",
      "loudness              0.08     0.29   0.23            0.19  \n",
      "mode                  0.02     0.03  -0.00           -0.02  \n",
      "speechiness           0.23     0.03   0.00           -0.01  \n",
      "acousticness         -0.02    -0.10  -0.22           -0.17  \n",
      "instrumentalness     -0.09    -0.33  -0.06           -0.08  \n",
      "liveness              1.00     0.01  -0.01           -0.03  \n",
      "valence               0.01     1.00   0.09            0.14  \n",
      "tempo                -0.01     0.09   1.00            0.09  \n",
      "time_signature       -0.03     0.14   0.09            1.00  \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical columns\n",
    "numerical_cols = df_dedup.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove 'Unnamed: 0' if present (it's just an index)\n",
    "if 'Unnamed: 0' in numerical_cols:\n",
    "    numerical_cols.remove('Unnamed: 0')\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_dedup[numerical_cols].corr()\n",
    "\n",
    "print(\"üìä CORRELATION MATRIX\")\n",
    "print(correlation_matrix.round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d01a9add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ CORRELATION WITH TARGET (popularity)\n",
      "Sorted by absolute correlation strength:\n",
      "instrumentalness     : -0.1275  üü° Weak\n",
      "loudness             : +0.0717  üü° Weak\n",
      "danceability         : +0.0643  üü° Weak\n",
      "speechiness          : -0.0471  üü¢ Very Weak\n",
      "acousticness         : -0.0388  üü¢ Very Weak\n",
      "time_signature       : +0.0369  üü¢ Very Weak\n",
      "duration_ms          : -0.0232  üîµ Negligible\n",
      "mode                 : -0.0162  üîµ Negligible\n",
      "liveness             : -0.0139  üîµ Negligible\n",
      "energy               : +0.0137  ‚ö™ None\n",
      "valence              : -0.0115  ‚ö™ None\n",
      "tempo                : +0.0073  ‚ö™ None\n",
      "key                  : +0.0034  ‚ö™ None\n"
     ]
    }
   ],
   "source": [
    "# CORRELATION WITH TARGET VARIABLE (POPULARITY)\n",
    "\n",
    "popularity_corr = correlation_matrix['popularity'].drop('popularity')\n",
    "\n",
    "print(\"üéØ CORRELATION WITH TARGET (popularity)\")\n",
    "print(\"Sorted by absolute correlation strength:\")\n",
    "\n",
    "# Sort by absolute correlation (descending)\n",
    "sorted_corr = sorted(popularity_corr.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Define dynamic thresholds based on your data\n",
    "# Since correlations are very small, we'll use percentiles\n",
    "corr_values = [abs(corr) for _, corr in sorted_corr]\n",
    "\n",
    "# Define thresholds based on data distribution\n",
    "# Top 25% get \"Weak\", next 25% \"Very Weak\", next 25% \"Negligible\", rest \"None\"\n",
    "if len(corr_values) >= 4:\n",
    "    thresholds = [\n",
    "        sorted(corr_values)[-int(len(corr_values)*0.25)],  # Top 25% threshold\n",
    "        sorted(corr_values)[-int(len(corr_values)*0.50)],  # Top 50% threshold\n",
    "        sorted(corr_values)[-int(len(corr_values)*0.75)],  # Top 75% threshold\n",
    "    ]\n",
    "else:\n",
    "    # Fallback for small datasets\n",
    "    thresholds = [0.1, 0.05, 0.02]\n",
    "\n",
    "for feature, corr in sorted_corr:\n",
    "    abs_corr = abs(corr)\n",
    "    \n",
    "    # Dynamic thresholding\n",
    "    if abs_corr >= thresholds[0]:\n",
    "        strength = \"üü° Weak\"\n",
    "    elif abs_corr >= thresholds[1]:\n",
    "        strength = \"üü¢ Very Weak\"\n",
    "    elif abs_corr >= thresholds[2]:\n",
    "        strength = \"üîµ Negligible\"\n",
    "    else:\n",
    "        strength = \"‚ö™ None\"\n",
    "\n",
    "    print(f\"{feature:20} : {corr:+.4f}  {strength}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ede0bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü° Weak:\n",
      "  ‚Ä¢ instrumentalness     : -0.1275\n",
      "  ‚Ä¢ loudness             : +0.0717\n",
      "  ‚Ä¢ danceability         : +0.0643\n",
      "\n",
      "üü¢ Very Weak:\n",
      "  ‚Ä¢ speechiness          : -0.0471\n",
      "  ‚Ä¢ acousticness         : -0.0388\n",
      "  ‚Ä¢ time_signature       : +0.0369\n",
      "\n",
      "üîµ Negligible:\n",
      "  ‚Ä¢ duration_ms          : -0.0232\n",
      "  ‚Ä¢ mode                 : -0.0162\n",
      "  ‚Ä¢ liveness             : -0.0139\n",
      "\n",
      "‚ö™ None:\n",
      "  ‚Ä¢ energy               : +0.0137\n",
      "  ‚Ä¢ valence              : -0.0115\n",
      "  ‚Ä¢ tempo                : +0.0073\n",
      "  ‚Ä¢ key                  : +0.0034\n"
     ]
    }
   ],
   "source": [
    "# Group features by strength\n",
    "groups = {\"üü° Weak\": [], \"üü¢ Very Weak\": [], \"üîµ Negligible\": [], \"‚ö™ None\": []}\n",
    "for feature, corr in sorted_corr:\n",
    "    abs_corr = abs(corr)\n",
    "    if abs_corr >= thresholds[0]:\n",
    "        groups[\"üü° Weak\"].append((feature, corr))\n",
    "    elif abs_corr >= thresholds[1]:\n",
    "        groups[\"üü¢ Very Weak\"].append((feature, corr))\n",
    "    elif abs_corr >= thresholds[2]:\n",
    "        groups[\"üîµ Negligible\"].append((feature, corr))\n",
    "    else:\n",
    "        groups[\"‚ö™ None\"].append((feature, corr))\n",
    "\n",
    "for strength_label, features in groups.items():\n",
    "    if features:\n",
    "        print(f\"\\n{strength_label}:\")\n",
    "        for feature, corr in features:\n",
    "            print(f\"  ‚Ä¢ {feature:20} : {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f673b6",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Skewness Analysis\n",
    "\n",
    "**Why?** Skewness measures asymmetry of distribution:\n",
    "- **Skewness = 0**: Symmetric (normal distribution)\n",
    "- **Skewness > 0**: Right-skewed (tail on right, most values on left)\n",
    "- **Skewness < 0**: Left-skewed (tail on left, most values on right)\n",
    "\n",
    "Highly skewed features may need transformation (log, sqrt) for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "769e4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä SKEWNESS ANALYSIS\n",
      "Interpretation:\n",
      "  |skew| > 1.0    ‚Üí    üü• Highly skewed\n",
      "  0.5 < |skew| ‚â§ 1.0 ‚Üí üü® Moderately skewed\n",
      "  |skew| ‚â§ 0.5    ‚Üí    üü© Fairly symmetric\n",
      "\n",
      "üü• HIGHLY SKEWED (|skew| > 1.0):\n",
      "  duration_ms          : +11.0728\n",
      "  speechiness          : +4.5458\n",
      "  time_signature       : -3.9988\n",
      "  liveness             : +2.0621\n",
      "  loudness             : -1.9599\n",
      "  instrumentalness     : +1.5640\n",
      "\n",
      "üü® MODERATELY SKEWED (0.5 < |skew| ‚â§ 1.0):\n",
      "  acousticness         : +0.6558\n",
      "  mode                 : -0.5697\n",
      "  energy               : -0.5600\n",
      "\n",
      "üü© FAIRLY SYMMETRIC (|skew| ‚â§ 0.5):\n",
      "  danceability         : -0.3983\n",
      "  tempo                : +0.1827\n",
      "  valence              : +0.1276\n",
      "  popularity           : +0.0709\n",
      "  key                  : -0.0001\n"
     ]
    }
   ],
   "source": [
    "# SKEWNESS ANALYSIS\n",
    "# Calculate skewness for all numerical columns\n",
    "# Rule of thumb: |skewness| > 1 is highly skewed\n",
    "\n",
    "skewness = df_dedup[numerical_cols].skew().sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"üìä SKEWNESS ANALYSIS\")\n",
    "print(\"Interpretation:\")\n",
    "print(\"  |skew| > 1.0    ‚Üí    üü• Highly skewed\")\n",
    "print(\"  0.5 < |skew| ‚â§ 1.0 ‚Üí üü® Moderately skewed\")\n",
    "print(\"  |skew| ‚â§ 0.5    ‚Üí    üü© Fairly symmetric\")\n",
    "\n",
    "\n",
    "# Group features by skewness level\n",
    "highly_skewed = []\n",
    "moderately_skewed = []\n",
    "fairly_symmetric = []\n",
    "\n",
    "for feature, skew in skewness.items():\n",
    "    abs_skew = abs(skew)\n",
    "    if abs_skew > 1.0:\n",
    "        highly_skewed.append((feature, skew))\n",
    "    elif abs_skew > 0.5:\n",
    "        moderately_skewed.append((feature, skew))\n",
    "    else:\n",
    "        fairly_symmetric.append((feature, skew))\n",
    "\n",
    "# Print Highly Skewed first (strongest issues)\n",
    "if highly_skewed:\n",
    "    print(\"\\nüü• HIGHLY SKEWED (|skew| > 1.0):\")\n",
    "    for feature, skew in highly_skewed:\n",
    "        print(f\"  {feature:20} : {skew:+.4f}\")\n",
    "    \n",
    "# Print Moderately Skewed\n",
    "if moderately_skewed:\n",
    "    print(\"\\nüü® MODERATELY SKEWED (0.5 < |skew| ‚â§ 1.0):\")\n",
    "    for feature, skew in moderately_skewed:\n",
    "        print(f\"  {feature:20} : {skew:+.4f}\")\n",
    "\n",
    "# Print Fairly Symmetric\n",
    "if fairly_symmetric:\n",
    "    print(\"\\nüü© FAIRLY SYMMETRIC (|skew| ‚â§ 0.5):\")\n",
    "    for feature, skew in fairly_symmetric:\n",
    "        print(f\"  {feature:20} : {skew:+.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5628361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà SUMMARY STATISTICS:\n",
      "Total features analyzed     : 14\n",
      "üü• Highly skewed            : 6 features\n",
      "üü® Moderately skewed        : 3 features\n",
      "üü© Fairly symmetric         : 5 features\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"üìà SUMMARY STATISTICS:\")\n",
    "print(f\"Total features analyzed     : {len(skewness)}\")\n",
    "print(f\"üü• Highly skewed            : {len(highly_skewed)} features\")\n",
    "print(f\"üü® Moderately skewed        : {len(moderately_skewed)} features\")\n",
    "print(f\"üü© Fairly symmetric         : {len(fairly_symmetric)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6538f0",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Outlier Detection (IQR Method)\n",
    "\n",
    "**Why?** Outliers can:\n",
    "- Distort statistical measures (mean, std)\n",
    "- Negatively impact model training\n",
    "- Sometimes indicate data errors\n",
    "\n",
    "**IQR Method:**\n",
    "- Q1 = 25th percentile\n",
    "- Q3 = 75th percentile\n",
    "- IQR = Q3 - Q1\n",
    "- Outliers: values < Q1 - 1.5√óIQR or > Q3 + 1.5√óIQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84223856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä OUTLIER DETECTION (IQR Method)\n",
      "Feature                      Q1         Q3        IQR   Outliers        %\n",
      "popularity               19.000     49.000     30.000         11    0.01%\n",
      "duration_ms          173040.000 264293.000  91253.000      4,225    4.71%\n",
      "danceability              0.450      0.692      0.242        474    0.53%\n",
      "energy                    0.457      0.853      0.396          0    0.00%\n",
      "loudness                -10.322     -5.108      5.214      5,026    5.60%\n",
      "speechiness               0.036      0.086      0.050     10,644   11.86%\n",
      "acousticness              0.017      0.625      0.608          0    0.00%\n",
      "instrumentalness          0.000      0.098      0.098     19,613   21.86%\n",
      "liveness                  0.098      0.279      0.181      6,981    7.78%\n",
      "valence                   0.249      0.682      0.433          0    0.00%\n",
      "tempo                    99.263    140.077     40.814        514    0.57%\n",
      "\n",
      "Feature with most outliers: instrumentalness (19,613 outliers)\n"
     ]
    }
   ],
   "source": [
    "# Identify outliers in each numerical column using the IQR method\n",
    "\n",
    "# Select audio features for outlier analysis (excluding IDs and indices)\n",
    "audio_features = ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness',\n",
    "                  'speechiness', 'acousticness', 'instrumentalness', 'liveness', \n",
    "                  'valence', 'tempo']\n",
    "\n",
    "print(\"üìä OUTLIER DETECTION (IQR Method)\")\n",
    "print(f\"{'Feature':<20} {'Q1':>10} {'Q3':>10} {'IQR':>10} {'Outliers':>10} {'%':>8}\")\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for col in audio_features:\n",
    "    if col in df_dedup.columns:\n",
    "        Q1 = df_dedup[col].quantile(0.25)\n",
    "        Q3 = df_dedup[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count outliers\n",
    "        outliers = df_dedup[(df_dedup[col] < lower_bound) | (df_dedup[col] > upper_bound)][col].count()\n",
    "        outlier_pct = (outliers / len(df_dedup)) * 100\n",
    "        \n",
    "        print(f\"{col:<20} {Q1:>10.3f} {Q3:>10.3f} {IQR:>10.3f} {outliers:>10,} {outlier_pct:>7.2f}%\")\n",
    "        \n",
    "        outlier_summary.append({\n",
    "            'Feature': col,\n",
    "            'Outlier_Count': outliers,\n",
    "            'Outlier_Percentage': outlier_pct\n",
    "        })\n",
    "\n",
    "# Create summary DataFrame\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier_Count', ascending=False)\n",
    "print(f\"\\nFeature with most outliers: {outlier_df.iloc[0]['Feature']} ({outlier_df.iloc[0]['Outlier_Count']:,} outliers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50297b",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£Feature-wise Statistics (Min, Max, Range)\n",
    "\n",
    "**Why?** Understanding the range of values helps:\n",
    "- Identify potential data errors (impossible values)\n",
    "- Understand feature scales (important for scaling later)\n",
    "- Spot anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ab27885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä FEATURE-WISE STATISTICS\n",
      "Feature                       Min          Max        Range         Mean\n",
      "--------------------------------------------------------------------------------\n",
      "popularity                  0.000      100.000      100.000       33.199\n",
      "duration_ms              8586.000  5237295.000  5228709.000   229144.366\n",
      "danceability                0.000        0.985        0.985        0.562\n",
      "energy                      0.000        1.000        1.000        0.634\n",
      "loudness                  -49.531        4.532       54.063       -8.499\n",
      "speechiness                 0.000        0.965        0.965        0.087\n",
      "acousticness                0.000        0.996        0.996        0.328\n",
      "instrumentalness            0.000        1.000        1.000        0.173\n",
      "liveness                    0.000        1.000        1.000        0.217\n",
      "valence                     0.000        0.995        0.995        0.469\n",
      "tempo                       0.000      243.372      243.372      122.058\n"
     ]
    }
   ],
   "source": [
    "# Calculate min, max, and range for each numerical feature\n",
    "\n",
    "print(\"üìä FEATURE-WISE STATISTICS\")\n",
    "print(f\"{'Feature':<20} {'Min':>12} {'Max':>12} {'Range':>12} {'Mean':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for col in audio_features:\n",
    "    if col in df_dedup.columns:\n",
    "        min_val = df_dedup[col].min()\n",
    "        max_val = df_dedup[col].max()\n",
    "        range_val = max_val - min_val\n",
    "        mean_val = df_dedup[col].mean()\n",
    "        \n",
    "        print(f\"{col:<20} {min_val:>12.3f} {max_val:>12.3f} {range_val:>12.3f} {mean_val:>12.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b3c28",
   "metadata": {},
   "source": [
    "### **What This Means for Preprocessing:**\n",
    "\n",
    "| Issue                                       | Solution                                    |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| `duration_ms` has huge range (8K to 5M)     | Scaling needed (StandardScaler or MinMaxScaler) |\n",
    "| `loudness` has negative values              | Scaling needed                                  |\n",
    "| Features on different scales                | Scaling will be essential before modeling   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832a6a1",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£  Grouped Statistics by Genre\n",
    "\n",
    "**Why?** Different genres may have different characteristics:\n",
    "- Do some genres have higher popularity?\n",
    "- Are certain genres more danceable/energetic?\n",
    "- This can inform feature engineering decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26d3fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MEAN STATISTICS BY GENRE (Top 15 by Popularity)\n",
      "                   popularity  danceability  energy  valence    tempo\n",
      "track_genre                                                          \n",
      "k-pop                  59.424         0.642   0.683    0.569  119.530\n",
      "pop-film               59.097         0.591   0.600    0.529  116.953\n",
      "metal                  56.422         0.481   0.841    0.425  129.480\n",
      "chill                  53.739         0.666   0.430    0.408  115.383\n",
      "latino                 51.789         0.755   0.712    0.622  121.420\n",
      "sad                    51.110         0.702   0.479    0.440  119.359\n",
      "grunge                 50.587         0.455   0.805    0.401  129.985\n",
      "indian                 49.765         0.586   0.555    0.448  115.207\n",
      "anime                  48.777         0.538   0.674    0.435  123.608\n",
      "emo                    48.500         0.601   0.668    0.441  126.998\n",
      "reggaeton              48.270         0.743   0.737    0.674  121.952\n",
      "sertanejo              47.861         0.593   0.702    0.613  126.008\n",
      "piano                  46.608         0.463   0.342    0.325  118.169\n",
      "progressive-house      46.538         0.617   0.822    0.356  125.841\n",
      "hard-rock              45.745         0.479   0.807    0.510  126.820\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean statistics for key features grouped by genre\n",
    "\n",
    "# Key features to analyze by genre\n",
    "key_features = ['popularity', 'danceability', 'energy', 'valence', 'tempo']\n",
    "\n",
    "# Group by genre and calculate mean\n",
    "genre_stats = df_dedup.groupby('track_genre')[key_features].mean().round(3)\n",
    "\n",
    "# Sort by popularity\n",
    "genre_stats_sorted = genre_stats.sort_values('popularity', ascending=False)\n",
    "\n",
    "print(\"üìä MEAN STATISTICS BY GENRE (Top 15 by Popularity)\")\n",
    "print(genre_stats_sorted.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeeb7f",
   "metadata": {},
   "source": [
    "Observation: \"Pop-film and K-pop are the most popular genres. Moderate audio features (not extreme) correlate with higher popularity suggesting mainstream appeal favors balanced, accessible music.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19e789ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MEAN STATISTICS BY GENRE (Bottom 10 by Popularity)\n",
      "                popularity  danceability  energy  valence    tempo\n",
      "track_genre                                                       \n",
      "idm                 15.522         0.527   0.556    0.303  123.340\n",
      "kids                14.771         0.779   0.614    0.682  121.795\n",
      "grindcore           14.522         0.272   0.926    0.217  119.162\n",
      "classical           13.362         0.386   0.197    0.392  108.026\n",
      "chicago-house       12.334         0.766   0.733    0.587  123.909\n",
      "detroit-techno      11.131         0.723   0.708    0.469  126.408\n",
      "latin                9.855         0.727   0.724    0.624  121.286\n",
      "jazz                 9.790         0.489   0.309    0.487  115.741\n",
      "romance              3.550         0.432   0.299    0.395  109.817\n",
      "iranian              2.225         0.300   0.545    0.153  114.618\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n MEAN STATISTICS BY GENRE (Bottom 10 by Popularity)\")\n",
    "print(genre_stats_sorted.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c34d31",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è‚É£ Explicit vs Non-Explicit Stats\n",
    "\n",
    "**Why?** Explicit content flag might influence:\n",
    "- Popularity (radio play, streaming restrictions)\n",
    "- Audio characteristics (energy, speechiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adc2977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EXPLICIT CONTENT DISTRIBUTION\n",
      "==================================================\n",
      "Non-Explicit (False): 82,036 tracks (91.4%)\n",
      "Explicit (True):      7,704 tracks (8.6%)\n",
      "==================================================\n",
      "\n",
      "üìä MEAN STATISTICS: EXPLICIT vs NON-EXPLICIT\n",
      "============================================================\n",
      "          popularity  danceability  energy  valence    tempo\n",
      "explicit                                                    \n",
      "False         32.853         0.556   0.627    0.470  122.096\n",
      "True          36.886         0.631   0.719    0.467  121.658\n",
      "============================================================\n",
      "\n",
      "üìà DIFFERENCE (Explicit - Non-Explicit):\n",
      "----------------------------------------\n",
      "  popularity: +4.033 ‚Üë\n",
      "  danceability: +0.075 ‚Üë\n",
      "  energy: +0.092 ‚Üë\n",
      "  valence: -0.003 ‚Üì\n",
      "  tempo: -0.438 ‚Üì\n"
     ]
    }
   ],
   "source": [
    "# Compare statistics between explicit and non-explicit tracks\n",
    "\n",
    "# Count of explicit vs non-explicit\n",
    "explicit_counts = df_dedup['explicit'].value_counts()\n",
    "\n",
    "print(\"üìä EXPLICIT CONTENT DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Non-Explicit (False): {explicit_counts.get(False, 0):,} tracks ({explicit_counts.get(False, 0)/len(df_dedup)*100:.1f}%)\")\n",
    "print(f\"Explicit (True):      {explicit_counts.get(True, 0):,} tracks ({explicit_counts.get(True, 0)/len(df_dedup)*100:.1f}%)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare mean statistics\n",
    "explicit_stats = df_dedup.groupby('explicit')[key_features].mean().round(3)\n",
    "\n",
    "print(\"\\nüìä MEAN STATISTICS: EXPLICIT vs NON-EXPLICIT\")\n",
    "print(\"=\" * 60)\n",
    "print(explicit_stats)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate difference\n",
    "if True in explicit_stats.index and False in explicit_stats.index:\n",
    "    diff = explicit_stats.loc[True] - explicit_stats.loc[False]\n",
    "    print(\"\\nüìà DIFFERENCE (Explicit - Non-Explicit):\")\n",
    "    print(\"-\" * 40)\n",
    "    for feat, val in diff.items():\n",
    "        direction = \"‚Üë\" if val > 0 else \"‚Üì\" if val < 0 else \"=\"\n",
    "        print(f\"  {feat}: {val:+.3f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660896fd",
   "metadata": {},
   "source": [
    "Insight: Explicit songs are slightly more popular (+4 points on average)\n",
    "- This binary feature requires no transformation and provides useful signal for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc75f6",
   "metadata": {},
   "source": [
    "---\n",
    "## üîü Key Distribution Analysis\n",
    "\n",
    "**Why?** Musical key (C, C#, D, etc.) might affect:\n",
    "- Song mood and feel\n",
    "- Popularity in certain genres\n",
    "\n",
    "Key mapping: 0=C, 1=C#/Db, 2=D, 3=D#/Eb, 4=E, 5=F, 6=F#/Gb, 7=G, 8=G#/Ab, 9=A, 10=A#/Bb, 11=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca125fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MUSICAL KEY DISTRIBUTION\n",
      "============================================================\n",
      "    Key_Name  Track_Count  Percentage  Avg_Popularity\n",
      "key                                                  \n",
      "7          G        10550       11.76           32.61\n",
      "0          C        10352       11.54           32.72\n",
      "2          D         9327       10.39           33.68\n",
      "9          A         8998       10.03           32.87\n",
      "1      C#/Db         8576        9.56           32.86\n",
      "5          F         7308        8.14           32.97\n",
      "4          E         7133        7.95           34.06\n",
      "11         B         7129        7.94           33.88\n",
      "6      F#/Gb         6139        6.84           33.48\n",
      "10     A#/Bb         5889        6.56           32.84\n",
      "8      G#/Ab         5570        6.21           33.79\n",
      "3      D#/Eb         2769        3.09           33.25\n",
      "\n",
      "üéµ Most common key: G (11.76%)\n",
      "üîù Highest avg popularity: E (34.06)\n",
      "üîª Lowest avg popularity: G (32.61)\n"
     ]
    }
   ],
   "source": [
    "# Analyze distribution of musical keys and their relationship with popularity\n",
    "\n",
    "# Key mapping\n",
    "key_names = {0: 'C', 1: 'C#/Db', 2: 'D', 3: 'D#/Eb', 4: 'E', 5: 'F',\n",
    "             6: 'F#/Gb', 7: 'G', 8: 'G#/Ab', 9: 'A', 10: 'A#/Bb', 11: 'B'}\n",
    "\n",
    "# Count and popularity by key\n",
    "key_stats = df_dedup.groupby('key').agg({\n",
    "    'track_id': 'count',\n",
    "    'popularity': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "key_stats.columns = ['Track_Count', 'Avg_Popularity']\n",
    "key_stats['Key_Name'] = key_stats.index.map(key_names)\n",
    "key_stats['Percentage'] = (key_stats['Track_Count'] / len(df_dedup) * 100).round(2)\n",
    "\n",
    "# Reorder columns\n",
    "key_stats = key_stats[['Key_Name', 'Track_Count', 'Percentage', 'Avg_Popularity']]\n",
    "key_stats = key_stats.sort_values('Track_Count', ascending=False)\n",
    "\n",
    "print(\"üìä MUSICAL KEY DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "print(key_stats)\n",
    "\n",
    "# Most and least popular keys\n",
    "most_popular_key = key_stats.sort_values('Avg_Popularity', ascending=False).iloc[0]\n",
    "least_popular_key = key_stats.sort_values('Avg_Popularity', ascending=True).iloc[0]\n",
    "\n",
    "print(f\"\\nüéµ Most common key: {key_stats.iloc[0]['Key_Name']} ({key_stats.iloc[0]['Percentage']}%)\")\n",
    "print(f\"üîù Highest avg popularity: {most_popular_key['Key_Name']} ({most_popular_key['Avg_Popularity']})\")\n",
    "print(f\"üîª Lowest avg popularity: {least_popular_key['Key_Name']} ({least_popular_key['Avg_Popularity']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413d698",
   "metadata": {},
   "source": [
    "- Conclusion : \"Musical key has negligible correlation (+0.003) with popularity. The ~2 point difference between keys is not meaningful. This feature is unlikely to improve model performance significantly.\n",
    "- I will consider DROPPING key in preprocessing to simplify the  model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a02c8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£Duration Analysis\n",
    "\n",
    "**Why?** Song duration might affect:\n",
    "- Streaming counts (shorter songs might get more replays)\n",
    "- Radio play eligibility\n",
    "- User engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a383a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DURATION ANALYSIS\n",
      "==================================================\n",
      "Minimum duration: 0.14 minutes (9 seconds)\n",
      "Maximum duration: 87.29 minutes\n",
      "Average duration: 3.82 minutes\n",
      "Median duration:  3.55 minutes\n",
      "Std deviation:    1.88 minutes\n",
      "==================================================\n",
      "\n",
      "üìä DURATION DISTRIBUTION:\n",
      "----------------------------------------\n",
      "  < 2 min (short):    5,514 tracks (6.1%)\n",
      "  2-3 min (standard): 20,478 tracks (22.8%)\n",
      "  3-4 min (standard): 32,186 tracks (35.9%)\n",
      "  4-5 min (medium):   17,970 tracks (20.0%)\n",
      "  > 5 min (long):     13,592 tracks (15.1%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze song duration patterns\n",
    "\n",
    "# Convert milliseconds to minutes for easier interpretation\n",
    "df_dedup['duration_min'] = df_dedup['duration_ms'] / 60000\n",
    "\n",
    "print(\"üìä DURATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Minimum duration: {df_dedup['duration_min'].min():.2f} minutes ({df_dedup['duration_ms'].min()/1000:.0f} seconds)\")\n",
    "print(f\"Maximum duration: {df_dedup['duration_min'].max():.2f} minutes\")\n",
    "print(f\"Average duration: {df_dedup['duration_min'].mean():.2f} minutes\")\n",
    "print(f\"Median duration:  {df_dedup['duration_min'].median():.2f} minutes\")\n",
    "print(f\"Std deviation:    {df_dedup['duration_min'].std():.2f} minutes\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Duration categories\n",
    "print(\"\\nüìä DURATION DISTRIBUTION:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  < 2 min (short):    {(df_dedup['duration_min'] < 2).sum():,} tracks ({(df_dedup['duration_min'] < 2).sum()/len(df_dedup)*100:.1f}%)\")\n",
    "print(f\"  2-3 min (standard): {((df_dedup['duration_min'] >= 2) & (df_dedup['duration_min'] < 3)).sum():,} tracks ({((df_dedup['duration_min'] >= 2) & (df_dedup['duration_min'] < 3)).sum()/len(df_dedup)*100:.1f}%)\")\n",
    "print(f\"  3-4 min (standard): {((df_dedup['duration_min'] >= 3) & (df_dedup['duration_min'] < 4)).sum():,} tracks ({((df_dedup['duration_min'] >= 3) & (df_dedup['duration_min'] < 4)).sum()/len(df_dedup)*100:.1f}%)\")\n",
    "print(f\"  4-5 min (medium):   {((df_dedup['duration_min'] >= 4) & (df_dedup['duration_min'] < 5)).sum():,} tracks ({((df_dedup['duration_min'] >= 4) & (df_dedup['duration_min'] < 5)).sum()/len(df_dedup)*100:.1f}%)\")\n",
    "print(f\"  > 5 min (long):     {(df_dedup['duration_min'] >= 5).sum():,} tracks ({(df_dedup['duration_min'] >= 5).sum()/len(df_dedup)*100:.1f}%)\")\n",
    "\n",
    "# Remove temporary column\n",
    "df_dedup.drop('duration_min', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798de2d",
   "metadata": {},
   "source": [
    "#### Understanding how duration relates to popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffa0d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create duration in minutes (temporary)\n",
    "df_dedup['duration_min'] = df_dedup['duration_ms'] / 60000\n",
    "\n",
    "# Create duration categories\n",
    "df_dedup['duration_category'] = pd.cut(\n",
    "    df_dedup['duration_min'],\n",
    "    bins=[0, 2, 3, 4, 5, df_dedup['duration_min'].max()],\n",
    "    labels=['Short (<2)', '2‚Äì3 min', '3‚Äì4 min', '4‚Äì5 min', 'Long (>5)'],\n",
    "    include_lowest=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d9583ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, median, std are of Target Variable : Popularity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Short (&lt;2)</th>\n",
       "      <td>5557</td>\n",
       "      <td>27.946014</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.043802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2‚Äì3 min</th>\n",
       "      <td>20518</td>\n",
       "      <td>32.600546</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.478855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3‚Äì4 min</th>\n",
       "      <td>32175</td>\n",
       "      <td>34.938462</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.379562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4‚Äì5 min</th>\n",
       "      <td>17924</td>\n",
       "      <td>34.766905</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.512619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long (&gt;5)</th>\n",
       "      <td>13566</td>\n",
       "      <td>30.057497</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.751167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean  median        std\n",
       "duration_category                                     \n",
       "Short (<2)          5557  27.946014    25.0  18.043802\n",
       "2‚Äì3 min            20518  32.600546    32.0  21.478855\n",
       "3‚Äì4 min            32175  34.938462    36.0  21.379562\n",
       "4‚Äì5 min            17924  34.766905    35.0  19.512619\n",
       "Long (>5)          13566  30.057497    28.0  18.751167"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which duration range has higher average / median popularity?\n",
    "print(\"mean, median, std are of Target Variable : Popularity\")\n",
    "duration_popularity_stats = (\n",
    "    df_dedup\n",
    "    .groupby('duration_category', observed=True)['popularity']\n",
    "    .agg(['count', 'mean', 'median', 'std'])\n",
    ")\n",
    "\n",
    "duration_popularity_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a3ec7",
   "metadata": {},
   "source": [
    "- popularity peaks for standard-length tracks (3‚Äì5 minutes), indicating a meaningful non-linear relationship with the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ac483",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£Percentile Analysis\n",
    "\n",
    "**Why?** Percentiles help to understand:\n",
    "- Distribution of values across the dataset\n",
    "- Where most of the data lies\n",
    "- Extreme values (1st and 99th percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac46051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PERCENTILE ANALYSIS\n",
      "====================================================================================================\n",
      "      popularity  duration_ms  danceability  energy  loudness  speechiness  \\\n",
      "1th          0.0     61871.85         0.123   0.027   -28.542        0.026   \n",
      "5th          0.0    112041.90         0.237   0.142   -18.862        0.028   \n",
      "10th         0.0    136853.00         0.318   0.251   -14.695        0.030   \n",
      "25th        19.0    173040.00         0.450   0.457   -10.322        0.036   \n",
      "50th        33.0    213295.50         0.576   0.676    -7.185        0.049   \n",
      "75th        49.0    264293.00         0.692   0.853    -5.108        0.086   \n",
      "90th        60.0    332718.60         0.782   0.942    -3.723        0.183   \n",
      "95th        67.0    394001.40         0.825   0.970    -3.000        0.284   \n",
      "99th        78.0    546010.98         0.904   0.993    -1.628        0.619   \n",
      "\n",
      "      acousticness  instrumentalness  liveness  valence    tempo  \n",
      "1th          0.000             0.000     0.041    0.033   65.165  \n",
      "5th          0.000             0.000     0.061    0.064   76.997  \n",
      "10th         0.001             0.000     0.075    0.118   83.219  \n",
      "25th         0.017             0.000     0.098    0.249   99.263  \n",
      "50th         0.188             0.000     0.132    0.457  122.013  \n",
      "75th         0.625             0.098     0.279    0.682  140.077  \n",
      "90th         0.880             0.854     0.446    0.843  165.968  \n",
      "95th         0.956             0.911     0.694    0.912  174.994  \n",
      "99th         0.992             0.958     0.950    0.965  193.652  \n"
     ]
    }
   ],
   "source": [
    "# Calculate key percentiles for important features\n",
    "\n",
    "percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "\n",
    "print(\"üìä PERCENTILE ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Calculate percentiles for key features\n",
    "percentile_df = df_dedup[audio_features].quantile([p/100 for p in percentiles]).round(3)\n",
    "percentile_df.index = [f\"{p}th\" for p in percentiles]\n",
    "\n",
    "print(percentile_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03fd6bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ POPULARITY PERCENTILE INSIGHTS:\n",
      "--------------------------------------------------\n",
      "  ‚Ä¢ 1% of songs have popularity ‚â§ 0\n",
      "  ‚Ä¢ 50% of songs have popularity ‚â§ 33 (median)\n",
      "  ‚Ä¢ 90% of songs have popularity ‚â§ 60\n",
      "  ‚Ä¢ Top 1% of songs have popularity > 78\n"
     ]
    }
   ],
   "source": [
    "# Specific insight for popularity\n",
    "print(\"\\nüéØ POPULARITY PERCENTILE INSIGHTS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  ‚Ä¢ 1% of songs have popularity ‚â§ {df_dedup['popularity'].quantile(0.01):.0f}\")\n",
    "print(f\"  ‚Ä¢ 50% of songs have popularity ‚â§ {df_dedup['popularity'].quantile(0.50):.0f} (median)\")\n",
    "print(f\"  ‚Ä¢ 90% of songs have popularity ‚â§ {df_dedup['popularity'].quantile(0.90):.0f}\")\n",
    "print(f\"  ‚Ä¢ Top 1% of songs have popularity > {df_dedup['popularity'].quantile(0.99):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446421e3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£Variance & Standard Deviation\n",
    "\n",
    "**Why?** These measure spread/dispersion:\n",
    "- High variance = data points spread far from mean\n",
    "- Low variance = data points clustered near mean\n",
    "- Important for feature scaling decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec62dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä VARIANCE & STANDARD DEVIATION\n",
      "                         Mean      Variance      Std_Dev\n",
      "duration_ms       229144.3656  1.275675e+10  112945.7803\n",
      "tempo                122.0581  9.070729e+02      30.1177\n",
      "popularity            33.1988  4.235628e+02      20.5806\n",
      "loudness              -8.4990  2.726420e+01       5.2215\n",
      "acousticness           0.3283  1.145000e-01       0.3383\n",
      "instrumentalness       0.1734  1.049000e-01       0.3238\n",
      "valence                0.4695  6.910000e-02       0.2629\n",
      "energy                 0.6345  6.580000e-02       0.2566\n",
      "liveness               0.2170  3.800000e-02       0.1949\n",
      "danceability           0.5622  3.120000e-02       0.1767\n",
      "speechiness            0.0874  1.280000e-02       0.1133\n",
      "============================================================\n",
      "INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "Highest variance: duration_ms (12756749295.82)\n",
      "Lowest variance: speechiness (0.0128)\n"
     ]
    }
   ],
   "source": [
    "# Calculate variance and std for numerical features\n",
    "\n",
    "variance = df_dedup[audio_features].var().round(4)\n",
    "std_dev = df_dedup[audio_features].std().round(4)\n",
    "mean_vals = df_dedup[audio_features].mean().round(4)\n",
    "\n",
    "spread_df = pd.DataFrame({\n",
    "    'Mean': mean_vals,\n",
    "    'Variance': variance,\n",
    "    'Std_Dev': std_dev\n",
    "}).sort_values('Variance', ascending=False)\n",
    "\n",
    "print(\"üìä VARIANCE & STANDARD DEVIATION\")\n",
    "print(spread_df)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Highest variance: {spread_df.index[0]} ({spread_df.iloc[0]['Variance']:.2f})\")\n",
    "print(f\"Lowest variance: {spread_df.index[-1]} ({spread_df.iloc[-1]['Variance']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18a242",
   "metadata": {},
   "source": [
    "Features with very different scales may need normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a929a",
   "metadata": {},
   "source": [
    "### Notes to Myself:\n",
    "-  **Observations (Feature Scaling & Normalization)**\n",
    "\n",
    "The features exhibit very different numeric scales, ranging from:\n",
    "\n",
    "- `duration_ms` with a standard deviation of ~113,000  \n",
    "- to `speechiness` with a standard deviation of ~0.11  \n",
    "\n",
    "`popularity`, my target variable, also operates on a scale very different from most input features and should not be used for scaling reference.\n",
    "\n",
    "Because of these scale differences:\n",
    "\n",
    "**Distance-based models** (KNN, K-means)  \n",
    "**Gradient-based models** (linear/logistic regression, SVM, neural networks)  \n",
    "\n",
    "If I choose them, these would be biased toward high-magnitude features without normalization.\n",
    "\n",
    "*[Very IMP] If I choose Tree-based models (Decision Trees, Random Forests, Gradient Boosting) are not sensitive to feature scale, so normalization is optional for them.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df489824",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£Zero/Near-Zero Values Count\n",
    "\n",
    "Some Spotify features have many zeros:\n",
    "- `instrumentalness`: Most songs have vocals (value near 0)\n",
    "- `speechiness`: Most songs aren't speech-heavy\n",
    "- This affects distribution and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56371a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ZERO & NEAR-ZERO VALUES ANALYSIS\n",
      "======================================================================\n",
      "Feature               Exactly 0      < 0.001       < 0.01        < 0.1\n",
      "----------------------------------------------------------------------\n",
      "danceability                157          157          157          624\n",
      "energy                        1          111          463        3,080\n",
      "speechiness                 157          157          157       70,976\n",
      "acousticness                 39        9,503       19,185       36,984\n",
      "instrumentalness         29,924       54,417       61,225       67,399\n",
      "liveness                      2            2            4       23,746\n",
      "valence                     176          313          384        7,465\n"
     ]
    }
   ],
   "source": [
    "# Count how many values are exactly 0 or very close to 0\n",
    "\n",
    "print(\"üìä ZERO & NEAR-ZERO VALUES ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Feature':<18} {'Exactly 0':>12} {'< 0.001':>12} {'< 0.01':>12} {'< 0.1':>12}\")\n",
    "print(\"-\" * 70)\n",
    "zero_one_features = ['danceability', 'energy', 'speechiness', 'acousticness', \n",
    "                     'instrumentalness', 'liveness', 'valence']\n",
    "for col in zero_one_features:\n",
    "    exact_zero = (df_dedup[col] == 0).sum()\n",
    "    near_zero_001 = (df_dedup[col] < 0.001).sum()\n",
    "    near_zero_01 = (df_dedup[col] < 0.01).sum()\n",
    "    near_zero_1 = (df_dedup[col] < 0.1).sum()\n",
    "    \n",
    "    print(f\"{col:<18} {exact_zero:>12,} {near_zero_001:>12,} {near_zero_01:>12,} {near_zero_1:>12,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec1e5b",
   "metadata": {},
   "source": [
    "###  Interpretation Notes for future:\n",
    "- **High zero/near-zero counts** indicate sparse or skewed features\n",
    "- **Transformation candidates:**\n",
    "  - `instrumentalness` ‚Üí binary / binning (many exact zeros)\n",
    "  - `speechiness` ‚Üí binning or quantile transform (heavy near-zero skew)\n",
    "  - `acousticness` ‚Üí log transformation (continuous with many near-zero values)\n",
    "  - `liveness`, `energy` ‚Üí optional log/power transform (if using linear models)\n",
    "  - `danceability`, `valence` ‚Üí no transformation required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa60dc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ Coefficient of Variation (CV)\n",
    "CV = (Std Dev / Mean) √ó 100\n",
    "- Allows comparison of variability across features with different scales\n",
    "- CV > 100% indicates high variability\n",
    "- Useful for comparing spread regardless of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8234806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COEFFICIENT OF VARIATION (CV)\n",
      "Interpretation:\n",
      "  CV < 20%   ‚Üí Low variability\n",
      "  CV 20-50%  ‚Üí Moderate variability\n",
      "  CV > 50%   ‚Üí High variability\n",
      "  CV > 100%  ‚Üí Very high variability\n",
      "instrumentalness   CV:   186.75%  üî¥ Very high\n",
      "speechiness        CV:   129.55%  üî¥ Very high\n",
      "acousticness       CV:   103.06%  üî¥ Very high\n",
      "liveness           CV:    89.82%  üü° High\n",
      "popularity         CV:    61.99%  üü° High\n",
      "valence            CV:    55.99%  üü° High\n",
      "duration_ms        CV:    49.29%  üü¢ Moderate\n",
      "energy             CV:    40.44%  üü¢ Moderate\n",
      "danceability       CV:    31.43%  üü¢ Moderate\n",
      "tempo              CV:    24.67%  üü¢ Moderate\n",
      "loudness           CV:   -61.44%  ‚úÖ Low\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CV = (std / mean) * 100 ‚Äî relative variability measure\n",
    "\n",
    "# Calculate CV for features with non-zero mean\n",
    "cv_data = []\n",
    "\n",
    "for col in audio_features:\n",
    "    mean = df_dedup[col].mean()\n",
    "    std = df_dedup[col].std()\n",
    "    \n",
    "    if mean != 0:\n",
    "        cv = (std / mean) * 100\n",
    "    else:\n",
    "        cv = np.nan\n",
    "    \n",
    "    cv_data.append({\n",
    "        'Feature': col,\n",
    "        'Mean': mean,\n",
    "        'Std_Dev': std,\n",
    "        'CV (%)': cv\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_data).sort_values('CV (%)', ascending=False)\n",
    "\n",
    "print(\"üìä COEFFICIENT OF VARIATION (CV)\")\n",
    "print(\"Interpretation:\")\n",
    "print(\"  CV < 20%   ‚Üí Low variability\")\n",
    "print(\"  CV 20-50%  ‚Üí Moderate variability\")\n",
    "print(\"  CV > 50%   ‚Üí High variability\")\n",
    "print(\"  CV > 100%  ‚Üí Very high variability\")\n",
    "\n",
    "for _, row in cv_df.iterrows():\n",
    "    cv = row['CV (%)']\n",
    "    if pd.isna(cv):\n",
    "        flag = \"Cannot calculate (mean=0)\"\n",
    "    elif cv > 100:\n",
    "        flag = \"üî¥ Very high\"\n",
    "    elif cv > 50:\n",
    "        flag = \"üü° High\"\n",
    "    elif cv > 20:\n",
    "        flag = \"üü¢ Moderate\"\n",
    "    else:\n",
    "        flag = \"‚úÖ Low\"\n",
    "    \n",
    "    print(f\"{row['Feature']:<18} CV: {cv:>8.2f}%  {flag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae885a",
   "metadata": {},
   "source": [
    "## Observation: CV Analysis Insights\n",
    "\n",
    " **VERY HIGH VARIABILITY (>100%)**\n",
    "1. **instrumentalness, speechiness, acousticness**  \n",
    "   - Insight: Extreme skew with many near-zero values mixed with few high values  \n",
    "   - Preprocessing: Logarithmic/power transformations, binning, or quantile encoding  \n",
    "   - Visualization: Use log-scale histograms or violin plots  \n",
    "   - Modeling: Consider tree-based models (handle skew better) or create binary flags\n",
    "\n",
    "**HIGH VARIABILITY (50-100%)**\n",
    "2. **liveness, popularity, valence**  \n",
    "   - Insight: Good spread but skewed distributions  \n",
    "   - Preprocessing: Moderate scaling (StandardScaler/RobustScaler)  \n",
    "   - Feature selection: Strong candidates for predictive power  \n",
    "   - Visualization: Box plots + distribution overlays\n",
    "\n",
    "**MODERATE VARIABILITY (20-50%)**\n",
    "3. **duration_ms, energy, danceability, tempo**  \n",
    "   - Insight: Balanced distributions with reasonable spread  \n",
    "   - Scaling: Standard normalization works well  \n",
    "   - Modeling: Reliable features for most algorithms  \n",
    "   - Encoding: Can be used directly without heavy transformation\n",
    "\n",
    "**LOW VARIABILITY (<20%)**\n",
    "4. **loudness** (negative CV due to negative mean)  \n",
    "   - Insight: Values cluster tightly around mean (-8.2)  \n",
    "   - Preprocessing: May need mean-centered scaling  \n",
    "   - Feature selection: Lower priority unless domain-important  \n",
    "   - Note: Negative CV indicates negative mean value\n",
    "\n",
    "**ACTIONABLE RECOMMENDATIONS**\n",
    "5. **Prioritization Strategy**:\n",
    "   - High CV features ‚Üí Transform first (log, bin, normalize)  \n",
    "   - Moderate CV features ‚Üí Scale appropriately  \n",
    "   - Low CV features ‚Üí Check for information value  \n",
    "   - Encoding: High CV features may benefit from binning  \n",
    "   - Feature selection: Use CV as variability filter alongside correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17091d7d",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary \n",
    "\n",
    "\"During EDA, I discovered 24,259 duplicate tracks (same song in multiple genres). To ensure model integrity and avoid data leakage, I removed duplicates ‚Äî keeping 89,741 unique tracks for modeling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = df_dedup.reset_index(drop=True)\n",
    "\n",
    "df_dedup.to_csv('../data/spotify_dedup.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
