{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2028d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spotify colors\n",
    "BG = \"#e1ece3\"\n",
    "PRIMARY = \"#62d089\"\n",
    "EMPHASIS = \"#457e59\"\n",
    "GRID = \"#a8b2a8\"\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": BG,\n",
    "    \"axes.facecolor\": BG,\n",
    "    \"axes.edgecolor\": BG,\n",
    "    \"axes.labelcolor\": \"#2b2b2b\",\n",
    "    \"xtick.color\": \"#2b2b2b\",\n",
    "    \"ytick.color\": \"#2b2b2b\",\n",
    "    \"grid.color\": GRID,\n",
    "    \"grid.alpha\": 0.4,\n",
    "    \"axes.grid\": True,\n",
    "    \"font.size\": 11\n",
    "})\n",
    "\n",
    "df = pd.read_csv('../data/spotify_dedup.csv')\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.patch.set_facecolor(BG)\n",
    "\n",
    "model_names = list(models.keys())\n",
    "train_r2 = [results_df[results_df['Model'] == name]['Train R²'].values[0] for name in model_names]\n",
    "test_r2 = [results_df[results_df['Model'] == name]['Test R²'].values[0] for name in model_names]\n",
    "rmse = [results_df[results_df['Model'] == name]['RMSE'].values[0] for name in model_names]\n",
    "\n",
    "colors = ['#a8d5ba', PRIMARY, EMPHASIS]\n",
    "\n",
    "# Plot 1: R² Comparison\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, train_r2, width, label='Train R²', color=PRIMARY, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "axes[0].bar(x + width/2, test_r2, width, label='Test R²', color=EMPHASIS, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "axes[0].set_xlabel('Models', fontweight='bold')\n",
    "axes[0].set_ylabel('R² Score', fontweight='bold')\n",
    "axes[0].set_title('R² Score Comparison', fontweight='bold', pad=15)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[0].legend(framealpha=0.95).get_frame().set_facecolor(BG)\n",
    "\n",
    "# Plot 2: RMSE Comparison\n",
    "axes[1].bar(model_names, rmse, color=colors, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "axes[1].set_xlabel('Models', fontweight='bold')\n",
    "axes[1].set_ylabel('RMSE', fontweight='bold')\n",
    "axes[1].set_title('RMSE Comparison (Lower is Better)', fontweight='bold', pad=15)\n",
    "axes[1].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "\n",
    "# Plot 3: Overfitting Analysis\n",
    "overfit = [t - te for t, te in zip(train_r2, test_r2)]\n",
    "axes[2].bar(model_names, overfit, color=colors, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "axes[2].axhline(y=0.05, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Overfit Threshold')\n",
    "axes[2].set_xlabel('Models', fontweight='bold')\n",
    "axes[2].set_ylabel('Train R² - Test R²', fontweight='bold')\n",
    "axes[2].set_title('Overfitting Analysis (Lower is Better)', fontweight='bold', pad=15)\n",
    "axes[2].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[2].legend(framealpha=0.95).get_frame().set_facecolor(BG)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e0fad",
   "metadata": {},
   "source": [
    "## ✅ Summary & Key Takeaways\n",
    "\n",
    "### Model Performance Linear Regression VS Random Forest\n",
    "\n",
    "**Best Configuration**:\n",
    "- Feature Set: **Top 12 features**\n",
    "- R² Score: **0.457** (45.7% variance explained)\n",
    "- RMSE: **15.07** popularity points\n",
    "- MAE: **10.46** popularity points\n",
    "\n",
    "**Hyperparameters**:\n",
    "```python\n",
    "{\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "```\n",
    "\n",
    "### Comparison with Linear Regression (Notebook 08)\n",
    "\n",
    "| Metric | Linear (Ridge) | Random Forest | Improvement |\n",
    "|--------|---------------|---------------|-------------|\n",
    "| R²     | 0.3231        | 0.4571        | **+41.5%** |\n",
    "| RMSE   | 16.83         | 15.07         | **-10.5%** |\n",
    "| MAE    | ~11.57*       | 10.46         | **-9.6%** |\n",
    "\n",
    "*Estimated from your linear regression output\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**1. Non-Linear Relationships Exist**\n",
    "- Random Forest captures **non-linear patterns** missed by linear models\n",
    "- 40%+ improvement in R² confirms complex interactions between features\n",
    "- Example: Genre × Audio features may have non-additive effects\n",
    "\n",
    "**2. Feature Importance Differs from Linear Coefficients**\n",
    "- **Linear Model** top features (from your output):\n",
    "  1. track_genre (11.57)\n",
    "  2. speechiness (-10.09)\n",
    "  3. danceability (7.28)\n",
    "\n",
    "- **Random Forest** top features:\n",
    "  1. track_genre (77%!)\n",
    "  2. acousticness (2.4%)\n",
    "  3. danceability (2.0%)\n",
    "\n",
    "- RF shows **genre dominance** more clearly (77% vs 11.57 coefficient)\n",
    "- Acousticness important in RF but not in linear model (non-linear effect?)\n",
    "\n",
    "**3. Feature Selection Had Minimal Impact**\n",
    "- Full: R² = 0.452\n",
    "- Reduced: R² = 0.456\n",
    "- Top: R² = 0.457\n",
    "- Only ~1% difference between all three sets\n",
    "- **Practical implication**: Use Top features (50% fewer with same performance)\n",
    "\n",
    "**4. Model Limitations**\n",
    "- Still explains only ~46% of variance\n",
    "- Remaining 54% likely due to:\n",
    "  - External factors (marketing, radio play, playlist placement)\n",
    "  - Temporal trends (release timing, viral moments)\n",
    "  - Subjective taste (cultural context, demographics)\n",
    "  - Artist popularity (brand recognition)\n",
    "\n",
    "### Next Steps (Notebook 10: Stacking Regressor)\n",
    "\n",
    "**Ensemble Strategy**:\n",
    "1. Combine Linear Regression + Random Forest predictions\n",
    "2. Use meta-learner to weight each model optimally\n",
    "3. Expected benefits:\n",
    "   - Linear model: Good for simple relationships\n",
    "   - Random Forest: Good for complex patterns\n",
    "   - Stacking: Best of both worlds\n",
    "\n",
    "**Expected Results**:\n",
    "- R² improvement: ~2-5% (historically typical for stacking)\n",
    "- Target: R² ≈ 0.47-0.50 if successful\n",
    "\n",
    "### Recommendations for Production\n",
    "\n",
    "**1. Use Top Feature Set**\n",
    "- 12 features instead of 24 (50% reduction)\n",
    "- Faster predictions (important for real-time applications)\n",
    "- Same performance as full set\n",
    "\n",
    "**2. Consider Genre-Specific Models**\n",
    "- Genre explains 77% of RF importance\n",
    "- Train separate models per genre for better predictions\n",
    "- Example: Pop model vs Metal model (different popularity patterns)\n",
    "\n",
    "**3. Feature Engineering Opportunities**\n",
    "- Current features plateau at ~46% R²\n",
    "- Consider adding:\n",
    "  - Artist popularity score\n",
    "  - Release date features (day of week, month, year)\n",
    "  - Playlist inclusion count\n",
    "  - Social media metrics\n",
    "\n",
    "**4. Hyperparameter Insights**\n",
    "- `max_depth=None` worked best (no overfitting)\n",
    "- Suggests dataset is large enough to support complex trees\n",
    "- `n_estimators=200` marginally better than 100\n",
    "- Diminishing returns beyond 200 trees (not tested but typical)\n",
    "\n",
    "### Time Complexity Note\n",
    "- Training time: ~33 minutes total (11 min × 3 feature sets)\n",
    "- 120 fits per set (24 configs × 5 folds)\n",
    "- Prediction time: <1 second for 30,000+ songs\n",
    "- Acceptable for most production scenarios"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
